{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>MSM-building Calculations</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MUST SHARE KERNEL WITH NOTEBOOK `00-load-data.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook loads tons of stuff into memory. There is some code in place elsewhere to just load and toss large data objects for each operation but this takes forever compared to storing data in memory and plotting from it using a computer with suitable RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Timer context managers\n",
    "# create one then call to late-bind\n",
    "# a description of the usage\n",
    "time_loadfile = \"loadfile\"\n",
    "time_calculation = \"calculate\"\n",
    "\n",
    "kwargs_tica = [\"lag\"]\n",
    "kwargs_kmeans = [\"k\"]\n",
    "\n",
    "da = analysis_directory\n",
    "\n",
    "if not da.is_dir():\n",
    "    \n",
    "    da.mkdir(parents=True)\n",
    "    \n",
    "blueback = colorama.Back.BLUE\n",
    "yellowback = colorama.Back.LIGHTYELLOW_EX\n",
    "whitetxt = colorama.Fore.WHITE\n",
    "bluetxt = colorama.Fore.BLUE\n",
    "blacktxt = colorama.Fore.BLACK\n",
    "whiteback = colorama.Back.WHITE\n",
    "resetback = colorama.Back.RESET\n",
    "resettxt = colorama.Fore.RESET\n",
    "rreset = resetback + resettxt\n",
    "\n",
    "ts1 = whiteback+bluetxt\n",
    "is1 = blueback+whitetxt\n",
    "\n",
    "\n",
    "def _thisone_tica(feat, setup):\n",
    "\n",
    "    return _model_name(feat, {\n",
    "        **{k:setup[\"kwargs\"][k] for k in kwargs_tica},\n",
    "        **({\"bes\":f\"{(setup['epochsize']*ns_per_step):.0f}\"}\n",
    "           if \"epochsize\" in setup else {}),\n",
    "    })\n",
    "\n",
    "\n",
    "def _thisone_kmeans(feat, setup):\n",
    "    \n",
    "    return _model_name(feat, {\n",
    "        **{f\"tica_{k}\": setup[\"input\"][\"kwargs\"][k] for k in kwargs_tica},\n",
    "        **{k          : setup[\"kwargs\"][k]          for k in kwargs_kmeans},\n",
    "    })\n",
    "\n",
    "\n",
    "def _thisone_mits(feat, setup):\n",
    "\n",
    "    inpsetup = setup[\"input\"]\n",
    "    \n",
    "    return _model_name(feat, {\n",
    "        **{f\"tica_{k}\": inpsetup[\"input\"][\"kwargs\"][k] for k in kwargs_tica},\n",
    "        **{f\"kmeans_{k}\": inpsetup[\"kwargs\"][k] for k in kwargs_kmeans},\n",
    "        **{\"lags\": _clean_list(setup[\"kwargs\"][\"lags\"])},\n",
    "    })\n",
    "\n",
    "\n",
    "def _thisone_msm(feat, setup):\n",
    "    \n",
    "    inpsetup = setup[\"input\"]\n",
    "    \n",
    "    return _model_name(feat, {\n",
    "        **{f\"tica_{k}\": inpsetup[\"input\"][\"kwargs\"][k] for k in kwargs_tica},\n",
    "        **{f\"kmeans_{k}\": inpsetup[\"kwargs\"][k] for k in kwargs_kmeans},\n",
    "        **{\"lag\": setup[\"kwargs\"][\"lag\"]},\n",
    "    })\n",
    "\n",
    "\n",
    "def _thisone_pcca(feat, setup):\n",
    "    \n",
    "    inpsetup = setup[\"input\"]\n",
    "    inpsetupinp = inpsetup[\"input\"]\n",
    "    \n",
    "    return _model_name(feat, {\n",
    "        **{f\"tica_{k}\": inpsetupinp[\"input\"][\"kwargs\"][k] for k in kwargs_tica},\n",
    "        **{f\"kmeans_{k}\": inpsetupinp[\"kwargs\"][k] for k in kwargs_kmeans},\n",
    "        **{\"lag\": inpsetup[\"kwargs\"][\"lag\"],\n",
    "           \"n_macrostate\": setup[\"kwargs\"][\"m\"]},\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TICA and VAMP\n",
    "\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n, (feat, name, dataset) in enumerate(aswa_tools.iter_models(all_models)):\n",
    "    \n",
    "    dds = da / name\n",
    "    \n",
    "    dtica = dds / \"tica\"\n",
    "    ftica = dtica / \"tica.pyemma\"\n",
    "\n",
    "    if not dds.is_dir():\n",
    "        dds.mkdir()\n",
    "    if not dtica.is_dir():\n",
    "        dtica.mkdir()\n",
    "    \n",
    "    for m, setup in enumerate(dataset[\"tica\"]):\n",
    "\n",
    "        timer = setup[\"timer\"] = Timer(#Heat.start_one(\n",
    "            description=True, verbose=True)\n",
    "\n",
    "        setup[\"hash\"] = thisone = _thisone_tica(feat, setup)\n",
    "        _ftica = ftica.with_suffix(\".%s\" % thisone)\n",
    "\n",
    "        if _ftica.is_file():\n",
    "            print(f\"Loading File: {_ftica}\")\n",
    "            with timer(yellowback+blacktxt+time_loadfile+rreset):\n",
    "                setup[\"result\"] = pyemma.load(_ftica)\n",
    "\n",
    "        else:\n",
    "            print(f\"Calculating and Saving to File: {_ftica}\")\n",
    "            try:\n",
    "                with timer(time_calculation):\n",
    "                    setup[\"result\"] = coor.tica(\n",
    "                        setup[\"input\"], **setup[\"kwargs\"])\n",
    "                    \n",
    "                setup[\"result\"].save(_ftica, save_streaming_chain=True)\n",
    "\n",
    "            except:\n",
    "                print(yellowback+blacktxt+\"Calculation failed!\"+rreset)\n",
    "                print(colorama.Back.LIGHTRED_EX+blacktxt+traceback.format_exc()+rreset)\n",
    "\n",
    "                \n",
    "print(colorama.Back.LIGHTBLACK_EX + colorama.Fore.BLUE + \"  DONE LOADING DATA  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-means and regular-space clusterings\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n, (feat, nm, dataset) in enumerate(aswa_tools.iter_models(all_models)):\n",
    "    \n",
    "    dds = da / nm\n",
    "\n",
    "    for setup in dataset[\"cluster_kmeans\"]:\n",
    "\n",
    "        dkmeans = dds / \"kmeans\"\n",
    "        fkmeans = dkmeans / \"kmeans.pyemma\"\n",
    "\n",
    "        if not dkmeans.is_dir():\n",
    "            dkmeans.mkdir(parents=True)\n",
    "\n",
    "        inp = setup[\"input\"][\"result\"]\n",
    "        setup[\"hash\"] = thisone = _thisone_kmeans(feat, setup)\n",
    "        _fkmeans = fkmeans.with_suffix(\".%s\" % thisone)\n",
    "        \n",
    "        timer = setup[\"timer\"] = Timer(\n",
    "            description=True, verbose=True)\n",
    "\n",
    "        if _fkmeans.is_file():\n",
    "            print(f\"Loading File: {_fkmeans}\")\n",
    "            with timer(yellowback+blacktxt+time_loadfile+rreset):\n",
    "                setup[\"result\"] = pyemma.load(_fkmeans)\n",
    "\n",
    "        else:\n",
    "            if not inp: continue\n",
    "\n",
    "            print(f\"Calculating and Saving to File: {_fkmeans}\")\n",
    "            inp._default_chunksize = 10000\n",
    "            tica_inp = inp.get_output(list(range(n_tica_dim)))\n",
    "            with timer(yellowback+blacktxt+time_calculation+rreset):\n",
    "                setup[\"result\"] = coor.cluster_kmeans(\n",
    "                    tica_inp, **setup[\"kwargs\"])\n",
    "\n",
    "            setup[\"result\"].save(_fkmeans, save_streaming_chain=True)\n",
    "\n",
    "\n",
    "print(colorama.Back.LIGHTBLACK_EX + colorama.Fore.BLUE + \"  DONE LOADING DATA  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Many MSMs calculated to examine Implied TimeScales\n",
    "----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyemma.msm.estimators import ImpliedTimescalesMatrix\n",
    "\n",
    "stepname = \"msm\"\n",
    "thiscalc = \"mits\"\n",
    "disc_methods = [\"kmeans\"]\n",
    "\n",
    "for feat, name, dataset in aswa_tools.iter_models(all_models):\n",
    "    \n",
    "    dds   = da / name\n",
    "    pmits = dds / stepname\n",
    "    fmits = pmits / f\"{thiscalc}.pyemma\"\n",
    "    dmits = dataset[thiscalc] = list()\n",
    "\n",
    "    if not pmits.is_dir():\n",
    "        pmits.mkdir(parents=True)\n",
    "\n",
    "    print(ts1+f\"MSMs for workflow: {name}\"+rreset)\n",
    "    for disc_method in disc_methods:\n",
    "        for inpsetup in dataset[f\"cluster_{disc_method}\"]:\n",
    "          \n",
    "            curmits = dict()\n",
    "            curmits[\"input\"] = inpsetup\n",
    "            curmits[\"timer\"] = timer = Timer(description=True, verbose=True)\n",
    "            curmits[\"kwargs\"] = dict(\n",
    "                lags=msm_lags,\n",
    "                reversible=reversible,\n",
    "                nits=10,\n",
    "                errors=\"bayes\",\n",
    "                nsamples=20,\n",
    "               # dt_traj=f\"{dataset['timestep']:0.2} ns\",\n",
    "                weights=\"empirical\",  # if nm==\"ltj\" else \"oom\",\n",
    "            )\n",
    "            \n",
    "            resmits = None\n",
    "            curmits[\"hash\"] = thisone = _thisone_mits(feat, curmits)\n",
    "            _fmits = fmits.with_suffix(f\".{thisone}\")\n",
    "            \n",
    "            if not _fmits.is_file():\n",
    "                \n",
    "                if not inpsetup[\"result\"]: continue\n",
    "                print(f\"{is1}Calculating & Saving:{rreset} {thisone}\")\n",
    "                with timer(yellowback+blacktxt+time_calculation+rreset):\n",
    "                    resmits = pyemma.msm.its(inpsetup[\"result\"].dtrajs, **kwargs)\n",
    "\n",
    "                resmits.save(_fmits)\n",
    "\n",
    "            else:\n",
    "                \n",
    "                print(is1+f\"Loading File:{rreset} {thisone}\")\n",
    "                with timer(yellowback+blacktxt+time_loadfile+rreset):\n",
    "                    resmits = pyemma.load(_fmits)\n",
    "\n",
    "            resmatrix = ImpliedTimescalesMatrix(resmits, n_macrostates, msm_lags)\n",
    "            curmits[\"result\"] = resmatrix\n",
    "            \n",
    "            dmits.append(curmits)\n",
    "            \n",
    "            \n",
    "print(colorama.Back.LIGHTBLACK_EX + colorama.Fore.BLUE + \"  DONE LOADING DATA  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index the msms separate from ITS objects for massive convenience\n",
    "  - just making separate object references to cleanup access\n",
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for feat, name, dataset in aswa_tools.iter_models(all_models):\n",
    "    \n",
    "    mms = dataset[\"msm\"] = list()\n",
    "    \n",
    "    for setup in dataset[\"mits\"]:\n",
    "        for mm in setup[\"result\"].its.models:\n",
    "\n",
    "            msmsetup = dict()\n",
    "            msmsetup[\"timer\"] = None\n",
    "            msmsetup[\"input\"] = setup[\"input\"]\n",
    "            msmsetup[\"result\"] = mm\n",
    "            msmsetup[\"kwargs\"] = {k:v for k,v in setup[\"kwargs\"].items() if k != \"lags\"}\n",
    "            msmsetup[\"kwargs\"].update({\"lag\": mm.lag})\n",
    "            msmsetup[\"hash\"] = thisone = _thisone_msm(feat, msmsetup)\n",
    "            mms.append(msmsetup)\n",
    "            \n",
    "\n",
    "print(colorama.Back.LIGHTBLACK_EX + colorama.Fore.BLUE + \"  DONE LOADING DATA  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCCA Calculation and Indexing\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for feat, name, dataset in aswa_tools.iter_models(all_models):\n",
    "    \n",
    "    dds   = da / name\n",
    "    ppcca = dds / \"pcca\"\n",
    "    fpcca = ppcca / \"pcca.pyemma\"\n",
    "    dpcca = dataset[\"pcca\"] = list()\n",
    "\n",
    "    if not ppcca.is_dir():\n",
    "        ppcca.mkdir(parents=True)\n",
    "\n",
    "    print(ts1+f\"MSMs for workflow: {name}\"+rreset)\n",
    "    for nma in n_macrostates:\n",
    "        for msmsetup in dataset[\"msm\"]:\n",
    "\n",
    "            pccasetup = dict()\n",
    "            pccasetup[\"input\"] = inp = msmsetup\n",
    "            pccasetup[\"kwargs\"] = dict(m=nma)\n",
    "            pccasetup[\"timer\"] = timer = Timer(description=True, verbose=True)\n",
    "            pccasetup[\"hash\"] = thisone = _thisone_pcca(feat, pccasetup)\n",
    "            \n",
    "            _fpcca = fpcca.with_suffix(f\".{thisone}\")\n",
    "            respcca = None\n",
    "            \n",
    "            if _fpcca.is_file():\n",
    "                if not inp[\"result\"]: continue\n",
    "                print(is1+f\"Loading File: {thisone}\"+rreset)\n",
    "                with timer(yellowback+blacktxt+time_loadfile+rreset):\n",
    "                    respcca = pyemma.load(_fpcca)\n",
    "                \n",
    "            else:\n",
    "                print(is1+f\"Calculating & Saving: {thisone}\"+rreset)\n",
    "                try:\n",
    "                    with timer(yellowback+blacktxt+time_calculation+rreset):\n",
    "                        respcca = inp[\"result\"].pcca(nma)\n",
    "\n",
    "                    respcca.save(_fpcca)\n",
    "                    \n",
    "                except:\n",
    "                    print(yellowback+blacktxt+\"Calculation failed!\"+rreset)\n",
    "                    print(colorama.Fore.LIGHTRED_EX+blacktxt+traceback.format_exc()+rreset)\n",
    "                \n",
    "            pccasetup[\"result\"] = respcca\n",
    "            dpcca.append(pccasetup)\n",
    "            \n",
    "            \n",
    "print(colorama.Back.LIGHTBLACK_EX + colorama.Fore.BLUE + \"  DONE LOADING DATA  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMM Calculation\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reorganize analysis profiling data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-2a96bfe73d21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcalc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tica\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mitto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_thisone_tica\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mcalc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"cluster_kmeans\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mitto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_thisone_kmeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0miterrer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msetup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcalc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "times = dict()\n",
    "\n",
    "for feat, name, dataset in aswa_tools.iter_models(all_models):\n",
    "    times[name] = dict()\n",
    "    for calc in (\"tica\", \"cluster_kmeans\", \"msm\", \"pcca\", \"hmm\"):\n",
    "\n",
    "        times[calc] = dict()\n",
    "        \n",
    "        if isinstance(dataset[calc], dict):\n",
    "            iterrer = dataset[calc].items()\n",
    "        elif isinstance(dataset[calc], list):\n",
    "            if calc == \"tica\": itto = _thisone_tica\n",
    "            elif calc == \"cluster_kmeans\": itto = _thisone_kmeans\n",
    "            else: raise ValueError\n",
    "            iterrer = iter((itto(feat, setup), setup) for setup in dataset[calc])\n",
    "        else:\n",
    "            raise TypeError\n",
    "            \n",
    "        for thisone, setup in iterrer:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for n, (feat, name, dataset) in enumerate(\n",
    "    aswa_tools.iter_models(all_models)\n",
    "):\n",
    "    for msmsetup in dataset[\"msm\"].items():\n",
    "        \n",
    "    dds = da / nm\n",
    "    dmits = dataset.setdefault(\"mits\", dict())\n",
    "\n",
    "    for disc_method in [\"kmeans\"]:\n",
    "        \n",
    "        pmits = dds / \"msm\"\n",
    "        fmits = pmits / \"mits.pyemma\"\n",
    "\n",
    "        if not pmits.is_dir():\n",
    "            pmits.mkdir(parents=True)\n",
    "\n",
    "        for i, inpsetup in enumerate(\n",
    "            dataset[\"cluster_%s\" % disc_method]\n",
    "        ):\n",
    "            chosen_tica_lag = inpsetup[\"input\"][\"kwargs\"][\"lag\"]\n",
    "            chosen_k = inpsetup[\"kwargs\"][\"k\"]\n",
    "            inp = inpsetup[\"result\"]\n",
    "\n",
    "            thisone = _model_naame(feat, {\n",
    "                \"tica_lag\":     chosen_tica_lag,\n",
    "                \"k\":            chosen_k,\n",
    "                \"tica_weights\": \"empirical\" if nm==\"ltj\" else \"koopman\",\n",
    "                \"reversible\":   reversible,\n",
    "                \"disc\":         disc_method,\n",
    "                \"msm_lags\":     _clean_list(msm_lags),\n",
    "            })\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''     for m, setup in enumerate(dataset[\"cluster_regspace\"]):\n",
    "            thisone = _model_name(feat, setup[\"kwargs\"])\n",
    "\n",
    "            # clear_output(wait=True)\n",
    "            print(colorama.Back.CYAN + \"Next is regspace clustering TICA\")\n",
    "            print(\n",
    "                colorama.Back.CYAN\n",
    "                + \"Calculated %d models so far\" % (n_kmeans * (1 + n) + m + n_regspaces * n)\n",
    "            )\n",
    "            print((\" - on to model %s\" % thisone) + colorama.Back.RESET)\n",
    "            print(\n",
    "                colorama.Fore.LIGHTGREEN_EX\n",
    "                + \" - number %d / %d (wrong 2nd number)\"\n",
    "                % (n_kmeans * n + m, (n_kmeans + n_regspaces) * len(all_models))\n",
    "            )\n",
    "\n",
    "            _fregspace = fregspace.with_suffix(\".%s\" % thisone)\n",
    "\n",
    "            setup[\"input\"] = aswa_tools.get_matching_input(\n",
    "                dataset[\"tica\"], key=\"lag\", val=chosen_tica_lag\n",
    "            )\n",
    "\n",
    "            if not setup[\"input\"]:\n",
    "                continue\n",
    "\n",
    "            # SUM TING WONG with TICA object\n",
    "            setup[\"input\"]._default_chunksize = 10000\n",
    "\n",
    "            tica_inp = setup[\"input\"].get_output(list(range(n_tica_dim)))\n",
    "\n",
    "            mindist = (\n",
    "                np.power(\n",
    "                    np.product(\n",
    "                        [\n",
    "                            mx - mn\n",
    "                            for mn, mx in zip(\n",
    "                                np.min(np.concatenate(tica_inp), axis=0),\n",
    "                                np.max(np.concatenate(tica_inp), axis=0),\n",
    "                            )\n",
    "                        ]\n",
    "                    ),\n",
    "                    1.0 / n_tica_dim,\n",
    "                )\n",
    "                / 25.0\n",
    "            )\n",
    "\n",
    "            setup[\"actual-dmin\"] = setup[\"kwargs\"][\"dmin\"] * mindist\n",
    "\n",
    "            if _fregspace.is_file():\n",
    "                print(\"Found Results File: {}\".format(_fregspace))\n",
    "\n",
    "                setup[\"result\"] = pyemma.load(_fregspace)\n",
    "\n",
    "            else:\n",
    "\n",
    "                print(\"Calculating and Saving to File: {}\".format(_fregspace))\n",
    "\n",
    "                setup[\"result\"] = aswa_tools.refined_regspace(\n",
    "                    tica_inp, mindist, **setup[\"kwargs\"]\n",
    "                )\n",
    "\n",
    "                setup[\"result\"].save(_fregspace, save_streaming_chain=True)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for n, (feat, nm, dataset) in enumerate(aswa_tools.iter_models(all_models)):\n",
    "\n",
    "    dmits = dataset.setdefault(\"mits\", dict())\n",
    "    dpits = dataset.setdefault(\"pits\", dict())\n",
    "    dhits = dataset.setdefault(\"hits\", dict())\n",
    "\n",
    "    dds = da / nm\n",
    "\n",
    "    for chosen_tica_lag in chosen_tica_lags:\n",
    "        for m, (clust_method, par_key) in enumerate(\n",
    "            [(\"regspace\", \"dmin\"), (\"kmeans\", \"k\")]\n",
    "        ):\n",
    "            mits = dmits.setdefault(clust_method, list())\n",
    "            pits = dpits.setdefault(clust_method, list())\n",
    "            hits = dhits.setdefault(clust_method, list())\n",
    "\n",
    "            # MSM\n",
    "            pmits = dds / \"msm\"\n",
    "            fmits = pmits / \"mits.pyemma\"\n",
    "\n",
    "            # PCCA\n",
    "            ppits = dds / \"pcca\"\n",
    "            fpits = ppits / \"pits.pyemma\"\n",
    "\n",
    "            # HMM\n",
    "            phits = dds / \"hmm\"\n",
    "            fhits = phits / \"hits.pyemma\"\n",
    "\n",
    "            for d in {pmits, ppits, phits}:\n",
    "                if not d.is_dir():\n",
    "                    d.mkdir(parents=True)\n",
    "\n",
    "            for i, setup in enumerate(dataset[\"cluster_%s\" % clust_method]):\n",
    "\n",
    "                _fmits = fmits.with_suffix(\n",
    "                    \".%s__msmlags-%s\"%(\n",
    "                        _model_name(feat,\n",
    "                            reduce(lambda x, y: dict(x, **y), (\n",
    "                                {\"weights\": \"empirical\"\n",
    "                                 if nm == \"ltj\" else \"koopman\"},\n",
    "                                {\"reversible\": reversible},\n",
    "                                {\"disc\": clust_method},\n",
    "                                setup[\"kwargs\"]))),\n",
    "                        _clean_list(msm_lags))\n",
    "                )\n",
    "\n",
    "                # MSM MITS\n",
    "                #   FIXME --> these don't check if exist already\n",
    "                curmits = dict()\n",
    "                curmits[\"par\"] = (par_key, setup[\"kwargs\"][par_key])\n",
    "                curmits[\"kwargs\"] = dict(\n",
    "                    lags=msm_lags,\n",
    "                    reversible=reversible,\n",
    "                    nits=10,\n",
    "                    errors=\"bayes\",\n",
    "                    weights=\"empirical\",  # if dataset[\"n_trajs\"]==1 else \"oom\",\n",
    "                )\n",
    "\n",
    "                if not _fmits.is_file():\n",
    "                    if not setup[\"result\"]:\n",
    "                        continue\n",
    "\n",
    "                    with timer(timer_calculate):\n",
    "                        resmits = pyemma.msm.its(\n",
    "                            setup[\"result\"].dtrajs,\n",
    "                            nsamples=20,\n",
    "                            **curmits[\"kwargs\"])\n",
    "\n",
    "                    resmits.save(_fmits)\n",
    "\n",
    "                else:\n",
    "                    resmits = pyemma.load(_fmits)\n",
    "\n",
    "                curmits[\"result\"] = resmits\n",
    "\n",
    "                mits.append(curmits)\n",
    "\n",
    "                # PCCA PITS\n",
    "                for msm in resmits.models:\n",
    "                    for nma in n_macrostates:\n",
    "                        _fpits = fpits.with_suffix(\"%s__%s\"%(\n",
    "                            _model_name(\n",
    "                                \"msmlag\": msm.lag,\n",
    "                                \"nstates\": nma,\n",
    "                            ), thisone,)\n",
    "                        )\n",
    "            \n",
    "            # HMM HITS\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            # PCCA COMPLICATED HERE\n",
    "            for msm in result.models:\n",
    "                for nma in n_macrostates:\n",
    "                    thisone = \"%s__nstates-%r\"%(\"%s-%d-%s\" % (\"msmlag-\",\n",
    "                        msm.lag, _model_name(feat, reduce(\n",
    "                            lambda x, y: dict(x, **y), (\n",
    "                                {\"weights\": \"empirical\" if nm is \"ltj\" else \"koopman\"},\n",
    "                                {\"reversible\": reversible},\n",
    "                                {k:v for k,v in setup[\"kwargs\"].items() if k != \"lags\"})))), nma)\n",
    "            \n",
    "                    _fpcca = fpits.with_suffix(\".%s-%s-%d__%s\" % (\n",
    "                        clust_method, par_key, setup[\"par\"][1], thisone))\n",
    "\n",
    "                    if _fpcca.is_file():\n",
    "                        resultlist.append(pyemma.load(_fpcca))\n",
    "                    else:\n",
    "                        result = msm.pcca(nma)\n",
    "                        result.save(_fpcca)\n",
    "                        resultlist.append(result)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "            # TODO PCCA HMM\n",
    "\n",
    "print(colorama.Back.LIGHTBLACK_EX + colorama.Fore.BLUE + \"  DONE LOADING DATA  \")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"for n, (feat, nm, dataset) in enumerate(aswa_tools.iter_models(all_models)):\n",
    "\n",
    "    dlits = dataset.get(\"its\", dict())\n",
    "    dpits = dataset.get(\"pits\", dict())\n",
    "    dhits = dataset.get(\"hits\", dict())\n",
    "\n",
    "    for m, (clust_method, par_key) in enumerate(\n",
    "        [(\"regspace\", \"dmin\"), (\"kmeans\", \"k\")]\n",
    "    ):\n",
    "        lits = dlits.get(clust_method, list())\n",
    "        pits = dpits.get(clust_method, list())\n",
    "        hits = dhits.get(clust_method, list())\n",
    "\n",
    "        # MSM\n",
    "        dds = da / nm\n",
    "        dmsm = dds / \"msm\" / (\"tica_lag_%d\" % chosen_tica_lag)\n",
    "        fits = dmsm / \"its-results.pyemma\"\n",
    "\n",
    "        # PCCA\n",
    "        dpits = dds / \"pcca\" / (\"tica_lag_%d\" % chosen_tica_lag)\n",
    "        fpits = dpits / \"pits-results.pyemma\"\n",
    "        \n",
    "        # HMM\n",
    "        dhits = dds / \"hmm\" / (\"tica_lag_%d\" % chosen_tica_lag)\n",
    "        fhits= dhits / \"hits-results.pyemma\"\n",
    "        \n",
    "        for d in {dmsm, dpits, dhmm}:\n",
    "            if not d.is_dir():\n",
    "                d.mkdir(parents=True)\n",
    "\n",
    "                \n",
    "        for i, setup in enumerate(dataset[\"cluster_%s\" % clust_method]):\n",
    "\n",
    "            thisone = \"%s-%s-%s\" % (\n",
    "                \"msmlags\",\n",
    "                \",\".join([str(d) for d in msm_lags]),\n",
    "                _model_name(\n",
    "                    feat,\n",
    "                    reduce(\n",
    "                        lambda x, y: dict(x, **y),\n",
    "                        (\n",
    "                            {\"weights\": \"empirical\" if nm is \"ltj\" else \"koopman\"},\n",
    "                            {\"reversible\": reversible},\n",
    "                            setup[\"kwargs\"],\n",
    "                        ),\n",
    "                    ),\n",
    "                ),\n",
    "            )\n",
    "\n",
    "            # clear_output(wait=True)\n",
    "            print(\n",
    "                colorama.Back.CYAN\n",
    "                + \"Now creating MSMs using clusterings\"\n",
    "                + \"as the discretization to state space\"\n",
    "            )\n",
    "            print(colorama.Back.CYAN + \"Calculated %d models so far\" % (m))\n",
    "            print((\" - on to model %s\" % thisone) + colorama.Back.RESET)\n",
    "            print(\n",
    "                colorama.Fore.LIGHTGREEN_EX\n",
    "                + \" - number %d / %d (wrong 2nd number)\"\n",
    "                % (n_kmeans * n + m, (n_kmeans + n_regspaces) * len(all_models))\n",
    "            )\n",
    "\n",
    "            _fits = fits.with_suffix(\".%s-%s\" % (clust_method, thisone))\n",
    "            dits = dict()\n",
    "            dits[\"par\"] = (par_key, setup[\"kwargs\"][par_key])\n",
    "            dits[\"kwargs\"] = dict(\n",
    "                lags=msm_lags,\n",
    "                reversible=reversible,\n",
    "                nits=10,\n",
    "                errors=\"bayes\",\n",
    "                weights=\"empirical\",  # if dataset[\"n_trajs\"]==1 else \"oom\",\n",
    "            )\n",
    "\n",
    "            if not _fits.is_file():\n",
    "                \n",
    "                if not setup[\"result\"]:\n",
    "                    continue\n",
    "\n",
    "                print(colorama.Back.BLUE + colorama.Fore.BLACK + \"drajs shape:\")\n",
    "                print(str(len(setup[\"result\"].dtrajs)))\n",
    "                print(\n",
    "                    pformat([dt.shape for dt in setup[\"result\"].dtrajs])\n",
    "                    + colorama.Back.RESET\n",
    "                )\n",
    "                print(\n",
    "                    colorama.Fore.LIGHTGREEN_EX\n",
    "                    + \"Calculating and Saving to File: {}\".format(_fits)\n",
    "                )\n",
    "\n",
    "                result1 = pyemma.msm.its(\n",
    "                    # dits[\"result\"] = pyemma.msm.its(\n",
    "                    # dits[\"input\"],\n",
    "                    setup[\"result\"].dtrajs,\n",
    "                    nsamples=20,\n",
    "                    **dits[\"kwargs\"])\n",
    "                \n",
    "                # could set up as a filepath that gets\n",
    "                # loaded as needed --> DMGR!!!\n",
    "                #dits[\"result\"] = _fits\n",
    "                result.save(_fits)\n",
    "\n",
    "            else:\n",
    "                print(\"Found Results File: {}\".format(_fits))\n",
    "                result = pyemma.load(_fits)\n",
    "                # dits[\"result\"] = _fits\n",
    "\n",
    "   #         # Reverse so both with increasing N clusters\n",
    "    #        if \"regspace\" in clust_method:\n",
    "     #           lits.insert(0, dits)\n",
    "      #      else:\n",
    "       #         lits.append(dits)\n",
    "                \n",
    "            dits[\"result\"] = result\n",
    "            \n",
    "            # PCCA COMPLICATED HERE\n",
    "            for msm in result.models:\n",
    "                for nma in n_macrostates:\n",
    "                    thisone = \"%s__nstates-%r\"%(\"%s-%d-%s\" % (\"msmlag-\",\n",
    "                        msm.lag, _model_name(feat, reduce(\n",
    "                            lambda x, y: dict(x, **y), (\n",
    "                                {\"weights\": \"empirical\" if nm is \"ltj\" else \"koopman\"},\n",
    "                                {\"reversible\": reversible},\n",
    "                                {k:v for k,v in setup[\"kwargs\"].items() if k != \"lags\"})))), nma)\n",
    "            \n",
    "                    _fpcca = fpits.with_suffix(\".%s-%s-%d__%s\" % (\n",
    "                        clust_method, par_key, setup[\"par\"][1], thisone))\n",
    "\n",
    "                    if _fpcca.is_file():\n",
    "                        resultlist.append(pyemma.load(_fpcca))\n",
    "                    else:\n",
    "                        result = msm.pcca(nma)\n",
    "                        result.save(_fpcca)\n",
    "                        resultlist.append(result)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "            # TODO PCCA HMM\n",
    "\n",
    "\n",
    "print(colorama.Back.LIGHTBLACK_EX + colorama.Fore.BLUE + \"  DONE LOADING DATA  \")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MANY PCCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for n, (feat, nm, dataset) in enumerate(aswa_tools.iter_models(all_models)):\n",
    "    dataset[\"pits\"] = dlpits = dict()\n",
    "\n",
    "    for m, (clust_method, par_key) in enumerate(\n",
    "        [(\"regspace\", \"dmin\"), (\"kmeans\", \"k\")]\n",
    "    ):\n",
    "        dlpits[clust_method] = lpits = list()\n",
    "\n",
    "        dds = da / nm\n",
    "        dmsm = dds / \"msm\" / (\"tica_lag_%d\" % chosen_tica_lag)\n",
    "        fits = dmsm / \"its-results.pyemma\"\n",
    "        dpits = dds / \"pcca\" / (\"tica_lag_%d\" % chosen_tica_lag)\n",
    "        fpits = dpits / \"pits-results.pyemma\"\n",
    "        #fbundle = dpcca / \"bundle-results.pyemma\"\n",
    "\n",
    "        if not dpits.is_dir():\n",
    "            dpits.mkdir(parents=True)\n",
    "\n",
    "        for i, setup in enumerate(dataset[\"its\"][clust_method]):\n",
    "\n",
    "            if isinstance(setup[\"result\"], Path):\n",
    "                print(colorama.Back.CYAN+\"Loading file %r\"%setup[\"result\"])\n",
    "                setup[\"result\"] = pyemma.load(setup[\"result\"])\n",
    "                \n",
    "            elif not setup[\"result\"]:\n",
    "                continue\n",
    "            \n",
    "            for nma in n_macrostates:\n",
    "                \n",
    "                dp = dict()\n",
    "                dp[\"par\"] = (setup[\"par\"], (\"nstates\", nma))\n",
    "                # NOTE THESE KWARGS NOT USED\n",
    "                #  - pyemma has PCCA object attached to MSM\n",
    "                #    and just doing stuff to work around\n",
    "                dp[\"kwargs\"] = {k:v for k,v in setup[\"kwargs\"].items()}\n",
    "                dp[\"result\"] = resultlist = list()\n",
    "                \n",
    "                for msm in setup[\"result\"].models:\n",
    "                    thisone = \"%s__nstates-%r\"%(\"%s-%d-%s\" % (\"msmlag-\",\n",
    "                        msm.lag, _model_name(feat, reduce(\n",
    "                            lambda x, y: dict(x, **y), (\n",
    "                                {\"weights\": \"empirical\" if nm is \"ltj\" else \"koopman\"},\n",
    "                                {\"reversible\": reversible},\n",
    "                                {k:v for k,v in setup[\"kwargs\"].items() if k != \"lags\"})))), nma)\n",
    "\n",
    "                    # stuck one at a time, later use dmgr\n",
    "                    # to organize on top of its objects\n",
    "                    _fpcca = fpits.with_suffix(\".%s-%s-%d__%s\" % (\n",
    "                        clust_method, par_key, setup[\"par\"][1], thisone))\n",
    "\n",
    "                    # clear_output(wait=True)\n",
    "                    print(\n",
    "                        colorama.Back.CYAN\n",
    "                        + \"Now calculating PCCA+ decomposition of MSM\"\n",
    "                    )\n",
    "                    print(colorama.Back.CYAN + \"Calculated %d models so far\" % (m))\n",
    "                    print((\" - on to model %s\" % thisone) + colorama.Back.RESET)\n",
    "                    print(\n",
    "                        colorama.Fore.LIGHTGREEN_EX\n",
    "                        + \" - number %d / %d (wrong 2nd number)\"\n",
    "                        % (n_kmeans * n + m, (n_kmeans + n_regspaces) * len(all_models))\n",
    "                    )\n",
    "\n",
    "                    if _fpcca.is_file():\n",
    "                        print(\"Found Results File: {}\".format(_fpcca))\n",
    "                        resultlist.append(pyemma.load(_fpcca))\n",
    "                    else:\n",
    "                        result = msm.pcca(nma)\n",
    "                        result.save(_fpcca)\n",
    "                        resultlist.append(result)\n",
    "                        \n",
    "                        \n",
    "\n",
    "print(colorama.Back.LIGHTBLACK_EX + colorama.Fore.BLUE + \"  DONE LOADING DATA  \")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many HMMs\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Save a \"failed\" file and loook at it if results file not found, change results tag to failed or something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ece5e4aeddb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhowmany\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mn_kmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cluster_kmeans\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mn_regspaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cluster_regspace\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_models' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO \n",
    "# AS INCREMENTAL FOLLOWING THE PCCA ABOVE!!\n",
    "\n",
    "howmany = 0\n",
    "n_kmeans = len(all_models[feat][nm][\"cluster_kmeans\"])\n",
    "n_regspaces = len(all_models[feat][nm][\"cluster_regspace\"])\n",
    "\n",
    "for feat, nm, dataset in aswa_tools.iter_models(all_models):\n",
    "\n",
    "    dataset[\"hits\"] = dlits = dict()\n",
    "\n",
    "    for clust_method, par_key in [(\"regspace\", \"dmin\"), (\"kmeans\", \"k\")]:\n",
    "        # for clust_method, par_key in [(\"kmeans\", \"k\")]:\n",
    "        # for clust_method, par_key in [(\"regspace\", \"dmin\")]:\n",
    "\n",
    "        dlits[clust_method] = lits = list()\n",
    "\n",
    "        dds = da / nm\n",
    "        dmsm = dds / \"hmm\" / (\"tica_lag_%d\" % chosen_tica_lag)\n",
    "        fits = dmsm / \"its-results.pyemma\"\n",
    "\n",
    "        if not dmsm.is_dir():\n",
    "            dmsm.mkdir(parents=True)\n",
    "\n",
    "        for n in n_macrostates:\n",
    "            for i, setup in enumerate(dataset[\"cluster_%s\" % clust_method]):\n",
    "                # clear_output(wait=True)\n",
    "                howmany += 1\n",
    "\n",
    "                thisone = \"%s-%s_%d-%s_%s-%s_%s-%s\" % (\n",
    "                    clust_method,\n",
    "                    \"nstates\",\n",
    "                    n,\n",
    "                    \"hmmlags\",\n",
    "                    \",\".join([str(d) for d in hmm_lags]),\n",
    "                    \"reversible\",\n",
    "                    str(False),\n",
    "                    _model_name(feat, setup[\"kwargs\"]),\n",
    "                )\n",
    "\n",
    "                print(colorama.Back.CYAN + \"Calculated %d models so far\" % (howmany))\n",
    "                print((\" - on to model %s\" % thisone) + colorama.Back.RESET)\n",
    "                print(\n",
    "                    colorama.Fore.LIGHTGREEN_EX\n",
    "                    + \" - number %d / %d (wrong 2nd number)\"\n",
    "                    % (\n",
    "                        howmany,\n",
    "                        (n_kmeans + n_regspaces) * n_macrostates[-1] * len(all_models),\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                _fits = fits.with_suffix(\".%s\" % thisone)\n",
    "\n",
    "                dits = dict()\n",
    "                dits[\"par\"] = ((par_key, setup[\"kwargs\"][par_key]), (\"nstates\", n))\n",
    "\n",
    "                dits[\"kwargs\"] = dict(\n",
    "                    lags=hmm_lags,\n",
    "                    nstates=n,\n",
    "                    reversible=False,\n",
    "                    # nits=3,\n",
    "                    errors=\"bayes\",\n",
    "                    nsamples=20,\n",
    "                )\n",
    "\n",
    "                dits[\"result\"] = False\n",
    "                print(\"checking for existing files\")\n",
    "\n",
    "                if not _fits.is_file():\n",
    "\n",
    "                    print(\n",
    "                        colorama.Back.MAGENTA\n",
    "                        + \"Calculating and Saving to File: {}\".format(_fits)\n",
    "                        + colorama.Back.RESET\n",
    "                    )\n",
    "\n",
    "                    try:\n",
    "                        #dits[\"input\"] = setup[\"result\"].dtrajs\n",
    "                        dits[\"input\"] = setup[\"input\"]\n",
    "\n",
    "                    except AttributeError:\n",
    "                        print(\n",
    "                            colorama.Back.RED + \"MODEL NOT FOUND\" + colorama.Back.RESET\n",
    "                        )\n",
    "\n",
    "                    try:\n",
    "                        # pyemma.msm.timescales_hmsm(\n",
    "                        dits[\"result\"] = pyemma.msm.timescales_hmsm(\n",
    "                            dits[\"input\"],\n",
    "                            **dits[\"kwargs\"]\n",
    "                            # )\n",
    "                            # dits[\"result\"].save(_fits)\n",
    "                        ).save(_fits)\n",
    "\n",
    "                    except:\n",
    "                        dits[\"result\"] = False\n",
    "\n",
    "                else:\n",
    "                    print(\n",
    "                        colorama.Back.GREEN\n",
    "                        + colorama.Fore.RESET\n",
    "                        + \"Found Results File: {}\".format(_fits)\n",
    "                        + colorama.Back.RESET\n",
    "                    )\n",
    "\n",
    "                    try:\n",
    "                        dits[\"result\"] = pyemma.load(_fits)\n",
    "\n",
    "                    except:\n",
    "                        dits[\"result\"] = False\n",
    "\n",
    "                    # dits[\"result\"] = _fits\n",
    "\n",
    "                if \"regspace\" in clust_method:\n",
    "                    lits.insert(0, dits)\n",
    "\n",
    "                else:\n",
    "                    lits.append(dits)\n",
    "\n",
    "\n",
    "print(colorama.Back.LIGHTBLACK_EX + colorama.Fore.BLUE + \"  DONE LOADING DATA  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\infty$ DONE\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(colorama.Back.LIGHTBLACK_EX + colorama.Fore.BLUE + \"  DONE LOADING DATA  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
