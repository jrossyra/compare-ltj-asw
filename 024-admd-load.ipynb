{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Loading data from AdaptiveMD workflow</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MUST SHARE KERNEL WITH NOTEBOOK `00-load-data.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import AdaptiveMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import adaptivemd as amd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Select only datasets with AdaptiveMD database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_with_mongo = lambda: list(filter(\n",
    "    lambda d: \"database\" in d[-1],\n",
    "    aswa_tools.iter_models(all_models)\n",
    "))\n",
    "\n",
    "n_mongos = len(w_with_mongo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load the TICA data computed from each round of adaptive sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[store.generators[TaskGenerator] : 2 object(s), store.files[File] : 548 object(s), store.resources[Resource] : 0 object(s), store.configurations[Configuration] : 2 object(s), store.models[Model] : 9 object(s), store.tasks[Task] : 527 object(s), store.workers[Worker] : 653 object(s), store.logs[LogEntry] : 1538 object(s), store.data[DataDict] : 14 object(s)]\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "[store.generators[TaskGenerator] : 2 object(s), store.files[File] : 548 object(s), store.resources[Resource] : 0 object(s), store.configurations[Configuration] : 2 object(s), store.models[Model] : 9 object(s), store.tasks[Task] : 527 object(s), store.workers[Worker] : 653 object(s), store.logs[LogEntry] : 1538 object(s), store.data[DataDict] : 14 object(s)]\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "n_evecs = 10\n",
    "\n",
    "for f,w,d in w_with_mongo():\n",
    "    dbpath = \"/\".join([d[\"directory\"], d[\"database\"]])\n",
    "    mongo  = aswa.MongoInstance(dbpath)\n",
    "    mongo.open_mongodb()\n",
    "    time.sleep(3)\n",
    "    p = amd.Project(d[\"projectname\"], cfg=\"summit\")\n",
    "    \n",
    "    d[\"workflowresults\"] = wr = dict()\n",
    "    wr[\"tica\"] = wrticas = list()\n",
    "    \n",
    "    # DEBUG if there is no data showing up\n",
    "    # uncomment break - check projname in\n",
    "    # datasetup.py is correct!! for example\n",
    "    #break\n",
    "    #print([s for s in p.storage.stores])\n",
    "    for m in sorted(p.models, key=lambda m: m.__time__):\n",
    "        wrticas.append({\n",
    "            \"lag\"   : m.data[\"tica\"][\"lagtime\"],\n",
    "            \"evecs\" : m.data[\"tica\"][\"eigenvectors\"],\n",
    "        })\n",
    "        #print(\"hello\")\n",
    "        \n",
    "    mongo.stop_mongodb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\infty$ DONE\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[100m\u001b[34m  DONE LOADING DATA  \n"
     ]
    }
   ],
   "source": [
    "print(colorama.Back.LIGHTBLACK_EX + \\\n",
    "      colorama.Fore.BLUE + \\\n",
    "      \"  DONE LOADING DATA  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-86c61ece5a95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mticklabelformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'{:.3f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mworkflow_ASdistribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkflow_figs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ASDistribution/{0}-{1}-{2}.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#>>>># 6.1- Frame selection probabilities for each AS round on TICA landscape:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#for wnm in notmaster(aa):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mSDs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "ticklabelformat = lambda num: '{:.3f}'.format(num).rstrip('0').rstrip('.')\n",
    "workflow_ASdistribution = os.path.join(workflow_figs, 'ASDistribution/{0}-{1}-{2}.png')\n",
    "#>>>># 6.1- Frame selection probabilities for each AS round on TICA landscape:\n",
    "#for wnm in notmaster(aa):\n",
    "SDs = dict()\n",
    "for wnm in {'XMa-3'}:\n",
    "    SDs[wnm] = sds = dict()\n",
    "    w = a[wnm]\n",
    "    nw = nworkloads(w)\n",
    "    dbpath = w['database']\n",
    "    mongo = aswa.MongoInstance(dbpath)\n",
    "    #mongo = MongoInstance(dbpath)\n",
    "    mongo.open_mongodb()\n",
    "    time.sleep(10)\n",
    "    project = adaptivemd.Project(w['projectname'])\n",
    "    ttrajs = w['ttrajs']\n",
    "    dtrajs  = np.array(w['dtrajs'])\n",
    "    Ms = list(project.models.sorted(lambda m: m.__time__))\n",
    "    for I,(r_start,r_stop) in enumerate(workflowpartition(w)):\n",
    "        sds[I] = sdl = list()\n",
    "        XY  = np.concatenate([\n",
    "            ttj[:,:2].T\n",
    "            for ttj in ttrajs[r_start:r_stop]], axis=1)\n",
    "        dta = np.concatenate(dtrajs[r_start:r_stop])\n",
    "        M   = Ms[I]\n",
    "        for i in range(1):\n",
    "        #for i in range(3):\n",
    "            fig, ax = tica_01_landscape(dict(title='AS Round {} Sampling Distribution on Anton TICA Landscape'.format(I)))\n",
    "            Z  = np.zeros(XY.shape[1])\n",
    "            sd = aswa.calc_xma_distribution(M)\n",
    "            sdl.append(sd)\n",
    "            #sd = calc_xma_distribution(M)\n",
    "            for mi in range(M['clustering']['k']):\n",
    "                Z[dta==mi] = sd[mi]\n",
    "            print(Z)\n",
    "            print(Z/np.max(Z))\n",
    "            maxprobability = np.max(Z)\n",
    "            Z /= maxprobability\n",
    "            sortedidx = np.argsort(Z)\n",
    "            cbticks = {0:'0', 0.5: ticklabelformat(maxprobability/2), 1: ticklabelformat(maxprobability)}\n",
    "            sc = ax.scatter(*XY[:,sortedidx], c=Z[sortedidx], vmin=0, vmax=maxprobability, s=1)\n",
    "            cb = fig.colorbar(sc, ticks=list(cbticks.keys()))\n",
    "            cb.set_label(\"Adaptive Sampling Probability\")\n",
    "            cb.ax.set_yticklabels(list(cbticks.values()))\n",
    "            savefig(workflow_ASdistribution.format(wnm, I, i), dpi=600)\n",
    "            plt.close()\n",
    "    mongo.stop_mongodb()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
