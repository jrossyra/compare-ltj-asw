{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>MSM-building Calculations</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MUST SHARE KERNEL WITH NOTEBOOK `00-load-data.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TICA and VAMP\n",
    "\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[46mStarting MSM Pipeline with TICA\n",
      "Creating an array of models\n",
      "\u001b[46m\u001b[30mCalculated 0 models so far\n",
      " - on to model invca__lag-500__dim-20\u001b[49m\n",
      "\u001b[92m - number 0 / 2 (wrong 2nd number)\n",
      "Found Results File: analyses/ltj/tica/results.invca__lag-500__dim-20\n",
      "\u001b[46m\u001b[30mCalculated 1 models so far\n",
      " - on to model invca__lag-1000__dim-20\u001b[49m\n",
      "\u001b[92m - number 1 / 2 (wrong 2nd number)\n",
      "Found Results File: analyses/ltj/tica/results.invca__lag-1000__dim-20\n",
      "\u001b[46m\u001b[30mCalculated 2 models so far\n",
      " - on to model invca__lag-500__dim-20__weights-koopman\u001b[49m\n",
      "\u001b[92m - number 2 / 2 (wrong 2nd number)\n",
      "Found Results File: analyses/xma_Ca/tica/results.invca__lag-500__dim-20__weights-koopman\n",
      "\u001b[46m\u001b[30mCalculated 3 models so far\n",
      " - on to model invca__lag-1000__dim-20__weights-koopman\u001b[49m\n",
      "\u001b[92m - number 3 / 2 (wrong 2nd number)\n",
      "Calculating and Saving to File: analyses/xma_Ca/tica/results.invca__lag-1000__dim-20__weights-koopman\n",
      "\u001b[43mCalculation failed!\n",
      "Saving the error in place of model: SOON! FIXME\n",
      "\u001b[49m\u001b[91mTraceback (most recent call last):\n",
      "  File \"<ipython-input-20-c556d1368d22>\", line 52, in <module>\n",
      "    setup[\"input\"], **setup[\"kwargs\"])\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/pyemma/coordinates/api.py\", line 1263, in tica\n",
      "    res.estimate(data, chunksize=cs)\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/pyemma/coordinates/transform/tica.py\", line 158, in estimate\n",
      "    return super(TICA, self).estimate(X, **kwargs)\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/pyemma/coordinates/data/_base/transformer.py\", line 215, in estimate\n",
      "    super(StreamingEstimationTransformer, self).estimate(X, **kwargs)\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/pyemma/coordinates/data/_base/streaming_estimator.py\", line 44, in estimate\n",
      "    super(StreamingEstimator, self).estimate(X, **kwargs)\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/pyemma/_base/estimator.py\", line 407, in estimate\n",
      "    self._model = self._estimate(X)\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/pyemma/coordinates/transform/tica.py\", line 205, in _estimate\n",
      "    covar.estimate(iterable, chunksize=self.chunksize, **kw)\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/pyemma/coordinates/data/_base/streaming_estimator.py\", line 44, in estimate\n",
      "    super(StreamingEstimator, self).estimate(X, **kwargs)\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/pyemma/_base/estimator.py\", line 407, in estimate\n",
      "    self._model = self._estimate(X)\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/pyemma/coordinates/estimation/covariance.py\", line 213, in _estimate\n",
      "    for data, weight in zip(it, it_weights):\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/pyemma/coordinates/data/_base/datasource.py\", line 1075, in __next__\n",
      "    raise InvalidDataInStreamException(msg)\n",
      "pyemma.coordinates.data._base.datasource.InvalidDataInStreamException: Found invalid values in chunk in trajectory index 0 at chunk [0, 1001] within frames (array([   0,    1,    2, ...,  998,  999, 1000]),).\n",
      "\n",
      "\u001b[46m\u001b[30mCalculated 4 models so far\n",
      " - on to model invca__lag-500__dim-20__weights-koopman\u001b[49m\n",
      "\u001b[92m - number 4 / 2 (wrong 2nd number)\n",
      "Found Results File: analyses/umi_Ca/tica/results.invca__lag-500__dim-20__weights-koopman\n",
      "\u001b[46m\u001b[30mCalculated 5 models so far\n",
      " - on to model invca__lag-1000__dim-20__weights-koopman\u001b[49m\n",
      "\u001b[92m - number 5 / 2 (wrong 2nd number)\n",
      "Found Results File: analyses/umi_Ca/tica/results.invca__lag-1000__dim-20__weights-koopman\n",
      "\u001b[100m\u001b[34m  DONE LOADING DATA  \n"
     ]
    }
   ],
   "source": [
    "da = analysis_directory\n",
    "if not da.is_dir():\n",
    "    da.mkdir()\n",
    "\n",
    "print(colorama.Back.CYAN+\"Starting MSM Pipeline with TICA\")\n",
    "print(\"Creating an array of models\")\n",
    "\n",
    "# uses last for `nm`,`feat` from kernel connection!!!\n",
    "n_ticas = len(all_models[feat][nm][\"tica\"])\n",
    "\n",
    "for n,(feat,nm,dataset) in enumerate(\n",
    "    aswa_tools.iter_models(all_models)\n",
    "):\n",
    "    dds = da / nm\n",
    "    dtica = dds / \"tica\"\n",
    "    ftica = dtica / \"results.pyemma\"\n",
    "    dvamp = dds / \"vamp\"\n",
    "    fvamp = dvamp / \"results.pyemma\"\n",
    "    \n",
    "    if not dds.is_dir():\n",
    "        dds.mkdir()\n",
    "    if not dtica.is_dir():\n",
    "        dtica.mkdir()\n",
    "    if not dvamp.is_dir():\n",
    "        dvamp.mkdir()\n",
    "\n",
    "    for m,setup in enumerate(dataset[\"tica\"]):\n",
    "        \n",
    "        thisone = _model_name(feat, setup[\"kwargs\"])\n",
    "        \n",
    "        #clear_output(wait=True)\n",
    "        print(colorama.Back.CYAN+colorama.Fore.BLACK+\\\n",
    "            \"Calculated %d models so far\"%(n_ticas*n+m))\n",
    "        print((\" - on to model %s\"%thisone)+\\\n",
    "            colorama.Back.RESET)\n",
    "        print(colorama.Fore.LIGHTGREEN_EX+\\\n",
    "            \" - number %d / %d (wrong 2nd number)\"%(\n",
    "            n_ticas*n+m,n_ticas*len(all_models)))\n",
    "        \n",
    "        _ftica = ftica.with_suffix(\".%s\"%thisone)\n",
    "        \n",
    "        if _ftica.is_file():\n",
    "            print(\"Found Results File: {}\".format(_ftica))\n",
    "            setup[\"result\"] = pyemma.load(_ftica)\n",
    "            \n",
    "        else:\n",
    "            print(\n",
    "    \"Calculating and Saving to File: {}\".format(_ftica))\n",
    "            \n",
    "            try:\n",
    "                setup[\"result\"] = coor.tica(\n",
    "                    setup[\"input\"], **setup[\"kwargs\"])\n",
    "                setup[\"result\"].save(\n",
    "                    _ftica, save_streaming_chain=True)\n",
    "\n",
    "            except:\n",
    "                print(\n",
    "    colorama.Back.YELLOW+\"Calculation failed!\")\n",
    "                print(\n",
    "    \"Saving the error in place of model: SOON! FIXME\")\n",
    "                print(\n",
    "    colorama.Back.RESET+colorama.Fore.LIGHTRED_EX+\\\n",
    "                    traceback.format_exc())\n",
    "\n",
    "#    for setup in dataset[\"vamp\"]:\n",
    " #       _fvamp = fvamp.with_suffix(\n",
    "  #          \".%s\"%_model_name(feat, setup[\"kwargs\"]))\n",
    "   #     \n",
    "    #    if _fvamp.is_file():\n",
    "     #       print(\"Found Results File: {}\".format(_fvamp))\n",
    "      #      setup[\"result\"] = pyemma.load(_fvamp)\n",
    "       #     \n",
    "        #else:\n",
    "         #   print(\"Calculating and Saving to File: {}\".format(_fvamp))\n",
    "          #  setup[\"result\"] = coor.vamp(setup[\"input\"], **setup[\"kwargs\"])\n",
    "           # setup[\"result\"].save(_fvamp, save_streaming_chain=True)\n",
    "\n",
    "print(colorama.Back.LIGHTBLACK_EX + \\\n",
    "      colorama.Fore.BLUE + \\\n",
    "      \"  DONE LOADING DATA  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-means and regular-space clusterings\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[46mNext is k-means clustering TICA\n",
      "\u001b[46mNext is k-means clustering TICA\n",
      "\u001b[46mCalculated 0 models so far\n",
      " - on to model invca__k-75__max_iter-100__stride-5\u001b[49m\n",
      "\u001b[92m - number 0 / 3 (wrong 2nd number)\n",
      "Found Results File: analyses/ltj/kmeans/tica_lag_1000/results.invca__k-75__max_iter-100__stride-5\n",
      "\u001b[46mNext is k-means clustering TICA\n",
      "\u001b[46mCalculated 1 models so far\n",
      " - on to model invca__k-300__max_iter-100__stride-5\u001b[49m\n",
      "\u001b[92m - number 1 / 3 (wrong 2nd number)\n",
      "Found Results File: analyses/ltj/kmeans/tica_lag_1000/results.invca__k-300__max_iter-100__stride-5\n",
      "\u001b[46mNext is k-means clustering TICA\n",
      "\u001b[46mCalculated 2 models so far\n",
      " - on to model invca__k-600__max_iter-100__stride-5\u001b[49m\n",
      "\u001b[92m - number 2 / 3 (wrong 2nd number)\n",
      "Found Results File: analyses/ltj/kmeans/tica_lag_1000/results.invca__k-600__max_iter-100__stride-5\n",
      "\u001b[46mk-means done, now regspace clustering TICA\n",
      "\u001b[46mNext is k-means clustering TICA\n",
      "\u001b[46mNext is k-means clustering TICA\n",
      "\u001b[46mCalculated 3 models so far\n",
      " - on to model invca__k-75__max_iter-100__stride-5\u001b[49m\n",
      "\u001b[92m - number 3 / 3 (wrong 2nd number)\n",
      "Calculating and Saving to File: analyses/xma_Ca/kmeans/tica_lag_1000/results.invca__k-75__max_iter-100__stride-5\n",
      "\u001b[46mNext is k-means clustering TICA\n",
      "\u001b[46mCalculated 4 models so far\n",
      " - on to model invca__k-300__max_iter-100__stride-5\u001b[49m\n",
      "\u001b[92m - number 4 / 3 (wrong 2nd number)\n",
      "Calculating and Saving to File: analyses/xma_Ca/kmeans/tica_lag_1000/results.invca__k-300__max_iter-100__stride-5\n",
      "\u001b[46mNext is k-means clustering TICA\n",
      "\u001b[46mCalculated 5 models so far\n",
      " - on to model invca__k-600__max_iter-100__stride-5\u001b[49m\n",
      "\u001b[92m - number 5 / 3 (wrong 2nd number)\n",
      "Calculating and Saving to File: analyses/xma_Ca/kmeans/tica_lag_1000/results.invca__k-600__max_iter-100__stride-5\n",
      "\u001b[46mk-means done, now regspace clustering TICA\n",
      "\u001b[46mNext is k-means clustering TICA\n",
      "\u001b[46mNext is k-means clustering TICA\n",
      "\u001b[46mCalculated 6 models so far\n",
      " - on to model invca__k-75__max_iter-100__stride-5\u001b[49m\n",
      "\u001b[92m - number 6 / 3 (wrong 2nd number)\n",
      "Found Results File: analyses/umi_Ca/kmeans/tica_lag_1000/results.invca__k-75__max_iter-100__stride-5\n",
      "\u001b[46mNext is k-means clustering TICA\n",
      "\u001b[46mCalculated 7 models so far\n",
      " - on to model invca__k-300__max_iter-100__stride-5\u001b[49m\n",
      "\u001b[92m - number 7 / 3 (wrong 2nd number)\n",
      "Found Results File: analyses/umi_Ca/kmeans/tica_lag_1000/results.invca__k-300__max_iter-100__stride-5\n",
      "\u001b[46mNext is k-means clustering TICA\n",
      "\u001b[46mCalculated 8 models so far\n",
      " - on to model invca__k-600__max_iter-100__stride-5\u001b[49m\n",
      "\u001b[92m - number 8 / 3 (wrong 2nd number)\n",
      "Found Results File: analyses/umi_Ca/kmeans/tica_lag_1000/results.invca__k-600__max_iter-100__stride-5\n",
      "\u001b[46mk-means done, now regspace clustering TICA\n",
      "\u001b[100m\u001b[34m  DONE LOADING DATA  \n"
     ]
    }
   ],
   "source": [
    "# uses last for `nm`,`feat` from kernel connection!!!\n",
    "n_kmeans    = len(all_models[feat][nm][\"cluster_kmeans\"])\n",
    "n_regspaces = len(all_models[feat][nm][\"cluster_regspace\"])\n",
    "\n",
    "for n,(feat,nm,dataset) in enumerate(\n",
    "    aswa_tools.iter_models(all_models)\n",
    "):\n",
    "    dds       = da / nm\n",
    "    dkmeans   = dds / \"kmeans\" / (\"tica_lag_%d\"%chosen_lag)\n",
    "    dregspace = dds / \"regspace\" / (\"tica_lag_%d\"%chosen_lag)\n",
    "    fkmeans   = dkmeans / \"results.pyemma\"\n",
    "    fregspace = dregspace / \"results.pyemma\"\n",
    "\n",
    "    if not dkmeans.is_dir():\n",
    "        dkmeans.mkdir(parents=True)\n",
    "\n",
    "    if not dregspace.is_dir():\n",
    "        dregspace.mkdir(parents=True)\n",
    "    \n",
    "    print(colorama.Back.CYAN+\\\n",
    "        \"Next is k-means clustering TICA\")\n",
    "\n",
    "    for m,setup in enumerate(dataset[\"cluster_kmeans\"]):\n",
    "        \n",
    "        thisone = _model_name(feat, setup[\"kwargs\"])\n",
    "        \n",
    "        print(colorama.Back.CYAN+\\\n",
    "            \"Next is k-means clustering TICA\")\n",
    "        print(colorama.Back.CYAN+\\\n",
    "            \"Calculated %d models so far\"%(n_kmeans*n+m))\n",
    "        print((\" - on to model %s\"%thisone)+\\\n",
    "            colorama.Back.RESET)\n",
    "        print(colorama.Fore.LIGHTGREEN_EX+\\\n",
    "            \" - number %d / %d (wrong 2nd number)\"%(\n",
    "            n_kmeans*n+m,(n_kmeans+n_regspaces)*len(\n",
    "                all_models)))\n",
    "\n",
    "        _fkmeans = fkmeans.with_suffix(\".%s\"%thisone)\n",
    "\n",
    "        setup[\"input\"] = aswa_tools.get_matching_input(\n",
    "            dataset[\"tica\"], key=\"lag\", val=chosen_lag)\n",
    "\n",
    "        if _fkmeans.is_file():\n",
    "            print(\"Found Results File: {}\".format(_fkmeans))\n",
    "            setup[\"result\"] = pyemma.load(_fkmeans)\n",
    "            \n",
    "        else:\n",
    "            print(\n",
    "    \"Calculating and Saving to File: {}\".format(_fkmeans))\n",
    "\n",
    "            if not setup[\"input\"]:\n",
    "                continue\n",
    "\n",
    "            # SUM TING WONG with TICA object\n",
    "            setup[\"input\"]._default_chunksize = 10000\n",
    "\n",
    "            tica_inp = setup[\"input\"].get_output(\n",
    "                list(range(n_tica_dim)))\n",
    "            \n",
    "            print(colorama.Fore.BLACK+colorama.Back.BLUE+\\\n",
    "                  pformat(len(tica_inp)))\n",
    "            print([pformat(ti.shape) for ti in tica_inp])\n",
    "            \n",
    "            setup[\"result\"] = coor.cluster_kmeans(\n",
    "                tica_inp, **setup[\"kwargs\"])\n",
    "\n",
    "            setup[\"result\"].save(\n",
    "                _fkmeans, save_streaming_chain=True)\n",
    "\n",
    "    print(colorama.Back.CYAN+\\\n",
    "        \"k-means done, now regspace clustering TICA\")\n",
    "\n",
    "    for m,setup in enumerate(\n",
    "        dataset[\"cluster_regspace\"]\n",
    "    ):\n",
    "        thisone = _model_name(feat, setup[\"kwargs\"])\n",
    "        \n",
    "        #clear_output(wait=True)\n",
    "        print(colorama.Back.CYAN+\\\n",
    "            \"Next is regspace clustering TICA\")\n",
    "        print(colorama.Back.CYAN+\\\n",
    "            \"Calculated %d models so far\"%(\n",
    "            n_kmeans*(1+n)+m+n_regspaces*n))\n",
    "        print((\" - on to model %s\"%thisone)+\\\n",
    "            colorama.Back.RESET)\n",
    "        print(colorama.Fore.LIGHTGREEN_EX+\\\n",
    "            \" - number %d / %d (wrong 2nd number)\"%(\n",
    "            n_kmeans*n+m,(n_kmeans+n_regspaces)*len(\n",
    "                all_models)))\n",
    "\n",
    "        _fregspace = fregspace.with_suffix(\".%s\"%thisone)\n",
    "\n",
    "        setup[\"input\"] = aswa_tools.get_matching_input(\n",
    "            dataset[\"tica\"], key=\"lag\", val=chosen_lag)\n",
    "                \n",
    "        if not setup[\"input\"]:\n",
    "            continue\n",
    "\n",
    "        # SUM TING WONG with TICA object\n",
    "        setup[\"input\"]._default_chunksize = 10000\n",
    "\n",
    "        tica_inp = setup[\"input\"].get_output(\n",
    "            list(range(n_tica_dim)))\n",
    "\n",
    "        mindist = np.power(np.product([\n",
    "            mx-mn for mn,mx in zip(\n",
    "                np.min(np.concatenate(tica_inp), axis=0),\n",
    "                np.max(np.concatenate(tica_inp), axis=0))\n",
    "        ]), 1./n_tica_dim) / 25.\n",
    "        \n",
    "        setup[\"actual-dmin\"] =setup[\"kwargs\"][\"dmin\"]*mindist\n",
    "            \n",
    "        if _fregspace.is_file():\n",
    "            print(\"Found Results File: {}\".format(\n",
    "                _fregspace))\n",
    "            \n",
    "            setup[\"result\"] = pyemma.load(_fregspace)\n",
    "            \n",
    "        else:\n",
    "\n",
    "            print(\"Calculating and Saving to File: {}\".format(\n",
    "                _fregspace))\n",
    "            \n",
    "            setup[\"result\"] = aswa_tools.refined_regspace(\n",
    "                tica_inp, mindist, **setup[\"kwargs\"])\n",
    "            \n",
    "            setup[\"result\"].save(\n",
    "                _fregspace, save_streaming_chain=True)\n",
    "            \n",
    "            \n",
    "print(colorama.Back.LIGHTBLACK_EX + \\\n",
    "      colorama.Fore.BLUE + \\\n",
    "      \"  DONE LOADING DATA  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Many MSMs calculated to examine Implied TimeScales\n",
    "----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reduce' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-816b2ae03f1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m             thisone = _model_name(\n\u001b[1;32m     22\u001b[0m                 \u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 reduce(lambda x,y: dict(x,**y), (\n\u001b[0m\u001b[1;32m     24\u001b[0m                     {\"weights\" : \"empirical\"\n\u001b[1;32m     25\u001b[0m                      \u001b[0;31m# OOM reweight seems absurdly slow...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reduce' is not defined"
     ]
    }
   ],
   "source": [
    "for n,(feat,nm,dataset) in enumerate(\n",
    "    aswa_tools.iter_models(all_models)\n",
    "):  \n",
    "    dataset[\"its\"] = dlits = dict()\n",
    "\n",
    "    for m,(clust_method, par_key) in enumerate(\n",
    "        [(\"regspace\", \"dmin\"), (\"kmeans\", \"k\")]\n",
    "    ):    \n",
    "        dlits[clust_method] = lits = list()\n",
    "        \n",
    "        dds = da / nm\n",
    "        dmsm = dds / \"msm\" / (\"tica_lag_%d\"%chosen_lag)\n",
    "        fits = dmsm / \"its-results.pyemma\"\n",
    "        \n",
    "        if not dmsm.is_dir():\n",
    "            dmsm.mkdir(parents=True)\n",
    "        \n",
    "        for i,setup in enumerate(\n",
    "            dataset[\"cluster_%s\"%clust_method]\n",
    "        ):\n",
    "            thisone = _model_name(\n",
    "                feat,\n",
    "                reduce(lambda x,y: dict(x,**y), (\n",
    "                    {\"weights\" : \"empirical\"\n",
    "                     # OOM reweight seems absurdly slow...\n",
    "                     #   if dataset[\"n_trajs\"]==1\n",
    "                    #    else \"oom\"\n",
    "                    },\n",
    "                    setup[\"kwargs\"])))\n",
    "            \n",
    "            \n",
    "            thisone = _model_name(feat,\n",
    "                {\"weights\":\"%s\"%(\"empirical\"\n",
    "                    if dataset[\"n_trajs\"]==1\n",
    "                    else \"oom\")}.update(setup[\"kwargs\"]))\n",
    "                    \n",
    "            #clear_output(wait=True)\n",
    "            print(colorama.Back.CYAN+\\\n",
    "                \"Now creating MSMs using clusterings\"+\\\n",
    "                \"as the discretization to state space\")\n",
    "            print(colorama.Back.CYAN+\\\n",
    "                \"Calculated %d models so far\"%(m))\n",
    "            print((\" - on to model %s\"%thisone)+\\\n",
    "                colorama.Back.RESET)\n",
    "            print(colorama.Fore.LIGHTGREEN_EX+\\\n",
    "                \" - number %d / %d (wrong 2nd number)\"%(\n",
    "                n_kmeans*n+m,(n_kmeans+n_regspaces)*len(\n",
    "                    all_models)))\n",
    "\n",
    "            _fits = fits.with_suffix(\n",
    "                \".%s-%s\"%(clust_method, thisone))\n",
    "            \n",
    "            dits           = dict()\n",
    "            \n",
    "            dits[\"par\"]    = (\n",
    "                par_key, setup[\"kwargs\"][par_key])\n",
    "            \n",
    "            dits[\"kwargs\"] = dict(\n",
    "                lags=tica_lags,\n",
    "                reversible=False,\n",
    "                nits=10,\n",
    "                errors=\"bayes\",\n",
    "                weights=\"empirical\" if dataset[\"n_trajs\"]==1 else \"oom\",\n",
    "            )\n",
    "            \n",
    "            if not _fits.is_file():\n",
    "                if not setup[\"result\"]: continue \n",
    "\n",
    "                print(\n",
    "colorama.Back.BLUE+colorama.Fore.BLACK+\"drajs shape:\")\n",
    "                print(\n",
    "str(len(setup[\"result\"].dtrajs)))\n",
    "                print(pformat([dt.shape\n",
    "for dt in setup[\"result\"].dtrajs])+colorama.Back.RESET)\n",
    "                print(colorama.Fore.LIGHTGREEN_EX+\\\n",
    "\"Calculating and Saving to File: {}\".format(_fits))\n",
    "                \n",
    "                pyemma.msm.its(\n",
    "                #dits[\"result\"] = pyemma.msm.its(\n",
    "                    #dits[\"input\"],\n",
    "                    setup[\"result\"].dtrajs,\n",
    "                    nsamples=20,\n",
    "                    **dits[\"kwargs\"]\n",
    "                ).save(_fits)\n",
    "                dits[\"result\"] = _fits\n",
    "                #dits[\"result\"].save(_fits)\n",
    "            \n",
    "            else:\n",
    "                print(\"Found Results File: {}\".format(_fits))\n",
    "                dits[\"result\"] = pyemma.load(_fits)\n",
    "                #dits[\"result\"] = _fits\n",
    "            \n",
    "            # Reverse so both with increasing N clusters\n",
    "            if \"regspace\" in clust_method:\n",
    "                lits.insert(0, dits)\n",
    "            else:\n",
    "                lits.append(dits)\n",
    "\n",
    "\n",
    "print(colorama.Back.LIGHTBLACK_EX + \\\n",
    "      colorama.Fore.BLUE + \\\n",
    "      \"  DONE LOADING DATA  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(colorama.Back.LIGHTBLACK_EX + \\\n",
    "      colorama.Fore.BLUE + \\\n",
    "      \"  DONE LOADING DATA  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Many HMMs\n",
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Save a \"failed\" file and loook at it if results file not found, change results tag to failed or something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reversible = False\n",
    "howmany = 0\n",
    "n_kmeans    = len(all_models[feat][nm][\"cluster_kmeans\"])\n",
    "n_regspaces = len(all_models[feat][nm][\"cluster_regspace\"])\n",
    "\n",
    "for feat,nm,dataset in aswa_tools.iter_models(all_models):\n",
    "\n",
    "    dataset[\"hits\"] = dlits = dict()\n",
    "\n",
    "    for clust_method, par_key in [\n",
    "        (\"regspace\", \"dmin\"), (\"kmeans\", \"k\")\n",
    "    ]:\n",
    "    #for clust_method, par_key in [(\"kmeans\", \"k\")]:\n",
    "    #for clust_method, par_key in [(\"regspace\", \"dmin\")]:\n",
    "    \n",
    "        dlits[clust_method] = lits = list()\n",
    "\n",
    "        dds = da / nm\n",
    "        dmsm = dds / \"hmm\" / (\"tica_lag_%d\"%chosen_lag)\n",
    "        fits = dmsm / \"its-results.pyemma\"\n",
    "\n",
    "        if not dmsm.is_dir():\n",
    "            dmsm.mkdir(parents=True)\n",
    "   \n",
    "        for n in n_macrostates:\n",
    "            for i,setup in enumerate(\n",
    "                dataset[\"cluster_%s\"%clust_method]\n",
    "            ):\n",
    "                #clear_output(wait=True)\n",
    "                howmany += 1\n",
    "                \n",
    "                thisone = \"%s-%s_%d-%s_%s-%s\"%(\n",
    "                    clust_method, \"nstates\", n,\n",
    "                    \"reversible\", str(reversible),\n",
    "                    _model_name(feat, setup[\"kwargs\"]))\n",
    "                \n",
    "                print(colorama.Back.CYAN + \\\n",
    "                    \"Calculated %d models so far\"%(howmany))\n",
    "                print((\" - on to model %s\"%thisone) + \\\n",
    "                    colorama.Back.RESET)\n",
    "                print(colorama.Fore.LIGHTGREEN_EX + \\\n",
    "    \" - number %d / %d (wrong 2nd number)\"%(howmany,\n",
    "    (n_kmeans+n_regspaces)*n_macrostates[-1]*len(all_models)))\n",
    "\n",
    "                _fits = fits.with_suffix(\".%s\"%thisone)\n",
    "\n",
    "                print(\"fitted\")\n",
    "                dits           = dict()\n",
    "                print(\"getting dtrajs\")\n",
    "                \n",
    "                print(\"dtrajs were gotten\")\n",
    "                dits[\"par\"]    = (\n",
    "                    (par_key, setup[\"kwargs\"][par_key]),\n",
    "                    (\"nstates\", n))\n",
    "\n",
    "                print(\"kwargs on it\")\n",
    "                dits[\"kwargs\"] = dict(\n",
    "                    lags=tica_lags,\n",
    "                    nstates=n,\n",
    "                    reversible=reversible,\n",
    "                    #nits=3,\n",
    "                    errors=\"bayes\",\n",
    "                    nsamples=20,\n",
    "                )\n",
    "\n",
    "                dits[\"result\"] = False\n",
    "                print(\"checking for existing files\")\n",
    "                \n",
    "                if not _fits.is_file():\n",
    "                    \n",
    "                    print(\n",
    "    colorama.Back.MAGENTA+\"Calculating and Saving to File: {}\".format(\n",
    "        _fits)+colorama.Back.RESET)\n",
    "                    \n",
    "                    try:\n",
    "     #                   ditsinput = setup[\"result\"].dtrajs\n",
    "                        dits[\"input\"]  = setup[\"result\"].dtrajs\n",
    "        \n",
    "                    except AttributeError:\n",
    "                        print(\n",
    "    colorama.Back.RED+\"MODEL NOT FOUND\"+colorama.Back.RESET)\n",
    "\n",
    "                    try:\n",
    "                        #pyemma.msm.timescales_hmsm(\n",
    "                        dits[\"result\"] = pyemma.msm.timescales_hmsm(\n",
    "                            dits[\"input\"],\n",
    "                            **dits[\"kwargs\"]\n",
    "                        #)\n",
    "                        #dits[\"result\"].save(_fits)\n",
    "                        ).save(_fits)\n",
    "                        \n",
    "                    except:\n",
    "                        dits[\"result\"] = False\n",
    "\n",
    "                else:\n",
    "                    print(\n",
    "    colorama.Back.GREEN+colorama.Fore.RESET+\"Found Results File: {}\".format(\n",
    "    _fits)+colorama.Back.RESET)\n",
    "                    \n",
    "                    try:\n",
    "                        dits[\"result\"] = pyemma.load(_fits)\n",
    "                        \n",
    "                    except:\n",
    "                        dits[\"result\"] = False\n",
    "                        \n",
    "                    #dits[\"result\"] = _fits\n",
    "\n",
    "                # Reverse so both with increasing N clusters\n",
    "                if \"regspace\" in clust_method:\n",
    "                    lits.insert(0, dits)\n",
    "                    \n",
    "                else:\n",
    "                    lits.append(dits)\n",
    "                    \n",
    "                    \n",
    "print(colorama.Back.LIGHTBLACK_EX + \\\n",
    "      colorama.Fore.BLUE + \\\n",
    "      \"  DONE LOADING DATA  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\infty$ DONE\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(colorama.Back.LIGHTBLACK_EX + \\\n",
    "      colorama.Fore.BLUE + \\\n",
    "      \"  DONE LOADING DATA  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
