{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>MSM-building Calculations</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MUST SHARE KERNEL WITH NOTEBOOK `00-load-data.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook loads tons of stuff into memory. There is some code in place elsewhere to just load and toss large data objects for each operation but this takes forever compared to storing data in memory and plotting from it using a computer with suitable RAM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TICA\n",
    "\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading File: analyses/umi_Ca_4/ltj/tica/tica.feat-invca__lag-10\n",
      "\u001b[103m\u001b[30m\u001b[49m\u001b[39mloadfile: 0.20564638078212738 seconds\n",
      "Loading File: analyses/umi_Ca_4/ltj/tica/tica.feat-invca__lag-25\n",
      "\u001b[103m\u001b[30m\u001b[49m\u001b[39mloadfile: 0.18059329502284527 seconds\n",
      "Loading File: analyses/umi_Ca_4/ltj/tica/tica.feat-invca__lag-50\n",
      "\u001b[103m\u001b[30m\u001b[49m\u001b[39mloadfile: 0.181124834343791 seconds\n",
      "Loading File: analyses/umi_Ca_4/ltj/tica/tica.feat-invca__lag-100\n",
      "\u001b[103m\u001b[30m\u001b[49m\u001b[39mloadfile: 0.18050900101661682 seconds\n",
      "Loading File: analyses/umi_Ca_4/ltj/tica/tica.feat-invca__lag-250\n",
      "\u001b[103m\u001b[30m\u001b[49m\u001b[39mloadfile: 0.18009809218347073 seconds\n",
      "Loading File: analyses/umi_Ca_4/ltj/tica/tica.feat-invca__lag-500\n",
      "\u001b[103m\u001b[30m\u001b[49m\u001b[39mloadfile: 0.18603893369436264 seconds\n",
      "Loading File: analyses/umi_Ca_4/ltj/tica/tica.feat-invca__lag-1000\n",
      "\u001b[103m\u001b[30m\u001b[49m\u001b[39mloadfile: 0.18014799617230892 seconds\n",
      "Loading File: analyses/umi_Ca_4/ltj/tica/tica.feat-invca__lag-2500\n",
      "\u001b[103m\u001b[30m\u001b[49m\u001b[39mloadfile: 0.27215127274394035 seconds\n",
      "Loading File: analyses/umi_Ca_4/xma_Ca_3/tica/tica.feat-invca__lag-10\n",
      "\u001b[103m\u001b[30m\u001b[49m\u001b[39mloadfile: 0.1464328095316887 seconds\n",
      "Loading File: analyses/umi_Ca_4/xma_Ca_3/tica/tica.feat-invca__lag-25\n",
      "\u001b[103m\u001b[30m\u001b[49m\u001b[39mloadfile: 0.10042298398911953 seconds\n",
      "Loading File: analyses/umi_Ca_4/xma_Ca_3/tica/tica.feat-invca__lag-50\n",
      "\u001b[103m\u001b[30m\u001b[49m\u001b[39mloadfile: 0.09988396987318993 seconds\n",
      "Loading File: analyses/umi_Ca_4/xma_Ca_3/tica/tica.feat-invca__lag-100\n",
      "\u001b[103m\u001b[30m\u001b[49m\u001b[39mloadfile: 0.10107455216348171 seconds\n",
      "Loading File: analyses/umi_Ca_4/xma_Ca_3/tica/tica.feat-invca__lag-250\n",
      "\u001b[103m\u001b[30m\u001b[49m\u001b[39mloadfile: 0.10076869837939739 seconds\n",
      "Loading File: analyses/umi_Ca_4/xma_Ca_3/tica/tica.feat-invca__lag-500\n",
      "\u001b[103m\u001b[30m\u001b[49m\u001b[39mloadfile: 0.10139050520956516 seconds\n",
      "Calculating and Saving to File: analyses/umi_Ca_4/xma_Ca_3/tica/tica.feat-invca__lag-1000\n",
      "LaggedCovariance(bessel=False, c00=True, c0t=True, chunksize=None,\n",
      "         column_selection=None, ctt=False, diag_only=False, lag=1000,\n",
      "         modify_data=False, ncov_max=inf, remove_constant_mean=None,\n",
      "         remove_data_mean=True, reversible=False, skip=0,\n",
      "         sparse_mode='auto', stride=1, weights=None)-estimating-withparams-{}: 0.65887082926929 seconds\n",
      "_KoopmanEstimator(chunksize=None, epsilon=1e-06, lag=1000, ncov_max=inf,\n",
      "         skip=0, stride=1)-estimating-withparams-{}: 0.6635454967617989 seconds\n",
      "LaggedCovariance(bessel=False, c00=True, c0t=True, chunksize=None,\n",
      "         column_selection=None, ctt=False, diag_only=False, lag=1000,\n",
      "         modify_data=False, ncov_max=inf, remove_constant_mean=None,\n",
      "         remove_data_mean=True, reversible=True, skip=0,\n",
      "         sparse_mode='auto', stride=1,\n",
      "         weights=<pyemma.coordinates.estimation.covariance.LaggedCovariance.weights.<locals>.compute_weights_streamer object at 0x7f129470cc18>)-estimating-withparams-{}: 0.03510865941643715 seconds\n",
      "TICA(commute_map=False, dim=20, epsilon=1e-06, kinetic_map=True, lag=1000,\n",
      "   ncov_max=inf, reversible=True, skip=0, stride=1, var_cutoff=0.95,\n",
      "   weights=<pyemma.coordinates.estimation.koopman._KoopmanWeights object at 0x7f129471bcc0>)-estimating-withparams-{}: 0.03662577271461487 seconds\n",
      "\u001b[103m\u001b[30mcalculate\u001b[49m\u001b[39m: 0.7048815060406923 seconds\n",
      "\u001b[103m\u001b[30mCalculation failed!\u001b[49m\u001b[39m\n",
      "\u001b[101m\u001b[30mTraceback (most recent call last):\n",
      "  File \"<ipython-input-25-92dc8248d158>\", line 26, in <module>\n",
      "    setup[\"result\"] = coor.tica(setup[\"input\"], **setup[\"kwargs\"])\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/pyemma/coordinates/api.py\", line 1263, in tica\n",
      "    res.estimate(data, chunksize=cs)\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/pyemma/coordinates/transform/tica.py\", line 158, in estimate\n",
      "    return super(TICA, self).estimate(X, **kwargs)\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/pyemma/coordinates/data/_base/transformer.py\", line 215, in estimate\n",
      "    super(StreamingEstimationTransformer, self).estimate(X, **kwargs)\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/pyemma/coordinates/data/_base/streaming_estimator.py\", line 44, in estimate\n",
      "    super(StreamingEstimator, self).estimate(X, **kwargs)\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/pyemma/_base/estimator.py\", line 413, in estimate\n",
      "    self._model = self._estimate(X)\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/pyemma/coordinates/transform/tica.py\", line 205, in _estimate\n",
      "    covar.estimate(iterable, chunksize=self.chunksize, **kw)\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/pyemma/coordinates/data/_base/streaming_estimator.py\", line 44, in estimate\n",
      "    super(StreamingEstimator, self).estimate(X, **kwargs)\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/pyemma/_base/estimator.py\", line 413, in estimate\n",
      "    self._model = self._estimate(X)\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/pyemma/coordinates/estimation/covariance.py\", line 213, in _estimate\n",
      "    for data, weight in zip(it, it_weights):\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/pyemma/coordinates/data/_base/datasource.py\", line 1075, in __next__\n",
      "    raise InvalidDataInStreamException(msg)\n",
      "pyemma.coordinates.data._base.datasource.InvalidDataInStreamException: Found invalid values in chunk in trajectory index 0 at chunk [0, 1001] within frames (array([   0,    1,    2, ...,  998,  999, 1000]),).\n",
      "\u001b[49m\u001b[39m\n",
      "Calculating and Saving to File: analyses/umi_Ca_4/xma_Ca_3/tica/tica.feat-invca__lag-2500\n",
      "LaggedCovariance(bessel=False, c00=True, c0t=True, chunksize=None,\n",
      "         column_selection=None, ctt=False, diag_only=False, lag=2500,\n",
      "         modify_data=False, ncov_max=inf, remove_constant_mean=None,\n",
      "         remove_data_mean=True, reversible=False, skip=0,\n",
      "         sparse_mode='auto', stride=1, weights=None)-estimating-withparams-{}: 0.0005741119384765625 seconds\n",
      "_KoopmanEstimator(chunksize=None, epsilon=1e-06, lag=2500, ncov_max=inf,\n",
      "         skip=0, stride=1)-estimating-withparams-{}: 0.0015805680304765701 seconds\n",
      "\u001b[103m\u001b[30mcalculate\u001b[49m\u001b[39m: 0.0036667250096797943 seconds\n",
      "\u001b[103m\u001b[30mCalculation failed!\u001b[49m\u001b[39m\n",
      "\u001b[101m\u001b[30mTraceback (most recent call last):\n",
      "  File \"<ipython-input-25-92dc8248d158>\", line 26, in <module>\n",
      "    setup[\"result\"] = coor.tica(setup[\"input\"], **setup[\"kwargs\"])\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/pyemma/coordinates/api.py\", line 1235, in tica\n",
      "    koop.estimate(data, chunksize=cs)\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/pyemma/coordinates/data/_base/streaming_estimator.py\", line 44, in estimate\n",
      "    super(StreamingEstimator, self).estimate(X, **kwargs)\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/pyemma/_base/estimator.py\", line 413, in estimate\n",
      "    self._model = self._estimate(X)\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/pyemma/coordinates/estimation/koopman.py\", line 99, in _estimate\n",
      "    self._covar.estimate(iterable, **kwargs)\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/pyemma/coordinates/data/_base/streaming_estimator.py\", line 44, in estimate\n",
      "    super(StreamingEstimator, self).estimate(X, **kwargs)\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/pyemma/_base/estimator.py\", line 413, in estimate\n",
      "    self._model = self._estimate(X)\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/pyemma/coordinates/estimation/covariance.py\", line 184, in _estimate\n",
      "    self.lag+self.skip))\n",
      "ValueError: None single dataset [longest=1001] is longer than lag+skip [2500].\n",
      "\u001b[49m\u001b[39m\n",
      "Loading File: analyses/umi_Ca_4/umi_Ca_3/tica/tica.feat-invca__lag-10\n",
      "\u001b[103m\u001b[30m\u001b[49m\u001b[39mloadfile: 0.8965899273753166 seconds\n",
      "Loading File: analyses/umi_Ca_4/umi_Ca_3/tica/tica.feat-invca__lag-25\n",
      "\u001b[103m\u001b[30m\u001b[49m\u001b[39mloadfile: 0.5868185758590698 seconds\n",
      "Loading File: analyses/umi_Ca_4/umi_Ca_3/tica/tica.feat-invca__lag-50\n",
      "\u001b[103m\u001b[30m\u001b[49m\u001b[39mloadfile: 0.5760769844055176 seconds\n",
      "Loading File: analyses/umi_Ca_4/umi_Ca_3/tica/tica.feat-invca__lag-100\n",
      "\u001b[103m\u001b[30m\u001b[49m\u001b[39mloadfile: 0.5939662307500839 seconds\n",
      "Loading File: analyses/umi_Ca_4/umi_Ca_3/tica/tica.feat-invca__lag-250\n",
      "\u001b[103m\u001b[30m\u001b[49m\u001b[39mloadfile: 0.5800944454967976 seconds\n",
      "Loading File: analyses/umi_Ca_4/umi_Ca_3/tica/tica.feat-invca__lag-500\n",
      "\u001b[103m\u001b[30m\u001b[49m\u001b[39mloadfile: 0.565563514828682 seconds\n",
      "Loading File: analyses/umi_Ca_4/umi_Ca_3/tica/tica.feat-invca__lag-1000\n",
      "\u001b[103m\u001b[30m\u001b[49m\u001b[39mloadfile: 0.5652129892259836 seconds\n",
      "Loading File: analyses/umi_Ca_4/umi_Ca_3/tica/tica.feat-invca__lag-2500\n",
      "\u001b[103m\u001b[30m\u001b[49m\u001b[39mloadfile: 0.5440869238227606 seconds\n",
      "Loading File: analyses/umi_Ca_4/umi_Ca_4/tica/tica.feat-invca__lag-10\n",
      "\u001b[103m\u001b[30m\u001b[49m\u001b[39mloadfile: 0.7296633031219244 seconds\n",
      "Loading File: analyses/umi_Ca_4/umi_Ca_4/tica/tica.feat-invca__lag-25\n",
      "\u001b[103m\u001b[30m\u001b[49m\u001b[39mloadfile: 0.5426039062440395 seconds\n",
      "Loading File: analyses/umi_Ca_4/umi_Ca_4/tica/tica.feat-invca__lag-50\n",
      "\u001b[103m\u001b[30m\u001b[49m\u001b[39mloadfile: 0.5227276962250471 seconds\n",
      "Loading File: analyses/umi_Ca_4/umi_Ca_4/tica/tica.feat-invca__lag-100\n",
      "\u001b[103m\u001b[30m\u001b[49m\u001b[39mloadfile: 0.5459426548331976 seconds\n",
      "Loading File: analyses/umi_Ca_4/umi_Ca_4/tica/tica.feat-invca__lag-250\n",
      "\u001b[103m\u001b[30m\u001b[49m\u001b[39mloadfile: 0.5440123230218887 seconds\n",
      "Loading File: analyses/umi_Ca_4/umi_Ca_4/tica/tica.feat-invca__lag-500\n",
      "\u001b[103m\u001b[30m\u001b[49m\u001b[39mloadfile: 0.5495548266917467 seconds\n",
      "Loading File: analyses/umi_Ca_4/umi_Ca_4/tica/tica.feat-invca__lag-1000\n",
      "\u001b[103m\u001b[30m\u001b[49m\u001b[39mloadfile: 0.5325181353837252 seconds\n",
      "Loading File: analyses/umi_Ca_4/umi_Ca_4/tica/tica.feat-invca__lag-2500\n",
      "\u001b[103m\u001b[30m\u001b[49m\u001b[39mloadfile: 0.5379520636051893 seconds\n",
      "\u001b[100m\u001b[34m  DONE LOADING DATA  \n"
     ]
    }
   ],
   "source": [
    "for feat, name, dataset in aswa_tools.iter_models(all_models):\n",
    "    \n",
    "    dds = da / name\n",
    "    dtica = dds / \"tica\"\n",
    "    ftica = dtica / \"tica.pyemma\"\n",
    "\n",
    "    if not dds.is_dir(): dds.mkdir()\n",
    "    if not dtica.is_dir(): dtica.mkdir()\n",
    "    \n",
    "    for setup in dataset[\"tica\"]:\n",
    "\n",
    "        setup[\"timer\"] = timer = Timer(description=True, verbose=True)\n",
    "        setup[\"hash\"] = thisone = _thisone_tica(feat, setup)\n",
    "        \n",
    "        _ftica = ftica.with_suffix(\".%s\" % thisone)\n",
    "\n",
    "        if _ftica.is_file():\n",
    "            print(f\"Loading File: {_ftica}\")\n",
    "            with timer(yellowback+blacktxt+rreset+time_loadfile):\n",
    "                setup[\"result\"] = pyemma.load(_ftica)\n",
    "\n",
    "        else:\n",
    "            print(f\"Calculating and Saving to File: {_ftica}\")\n",
    "            try:\n",
    "                with timer(yellowback+blacktxt+time_calculation+rreset):\n",
    "                    setup[\"result\"] = coor.tica(setup[\"input\"], **setup[\"kwargs\"])\n",
    "                    \n",
    "                setup[\"result\"].save(_ftica, save_streaming_chain=True)\n",
    "\n",
    "            except:\n",
    "                print(yellowback+blacktxt+\"Calculation failed!\"+rreset)\n",
    "                print(er1+traceback.format_exc()+rreset)\n",
    "\n",
    "                \n",
    "print(dn1+\"  DONE LOADING DATA  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-means and regular-space clusterings\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating and Saving to File: analyses/umi_Ca_4/ltj/kmeans/kmeans.feat-invca__tica_lag-10__k-75\n",
      "KmeansClustering(clustercenters=array([], dtype=float32),\n",
      "         fixed_seed=2125135720, init_strategy='kmeans++', keep_data=False,\n",
      "         max_iter=100, metric='euclidean', n_clusters=75, n_jobs=1,\n",
      "         oom_strategy='memmap', skip=0, stride=5, tolerance=1e-05)-estimating-withparams-{}: 72.48660627193749 seconds\n",
      "\u001b[103m\u001b[30mcalculate\u001b[49m\u001b[39m: 72.56986899673939 seconds\n",
      "25-02-21 07:19:14 pyemma.coordinates.clustering.kmeans.KmeansClustering[61] ERROR    During saving the object KmeansClustering(clustercenters=array([[ 1.18436,  0.58214, ..., -0.15209,  0.61814],\n",
      "       [-0.21009, -0.0801 , ..., -0.06922, -0.02856],\n",
      "       ...,\n",
      "       [ 1.0011 ,  1.11453, ..., -0.45965,  0.40788],\n",
      "       [ 1.00974,  2.62235, ...,  1.54048, -1.06036]], dtype=float32),\n",
      "         fixed_seed=2125135720, init_strategy='kmeans++', keep_data=False,\n",
      "         max_iter=100, metric='euclidean', n_clusters=75, n_jobs=1,\n",
      "         oom_strategy='memmap', skip=0, stride=5, tolerance=1e-05)\") the following error occurred: Unable to create file (unable to open file: name = 'analyses/umi_Ca_4/ltj/kmeans/kmeans.feat-invca__tica_lag-10__k-75', errno = 2, error message = 'No such file or directory', flags = 15, o_flags = c2)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/h5py/_hl/files.py\", line 182, in make_fid\n",
      "    fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5f.pyx\", line 85, in h5py.h5f.open\n",
      "OSError: Unable to open file (unable to open file: name = 'analyses/umi_Ca_4/ltj/kmeans/kmeans.feat-invca__tica_lag-10__k-75', errno = 2, error message = 'No such file or directory', flags = 1, o_flags = 2)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/pyemma/_base/serialization/serialization.py\", line 240, in save\n",
      "    with H5File(file_name=file_name, mode='a') as f:\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/pyemma/_base/serialization/h5file.py\", line 41, in __init__\n",
      "    self._file = h5py.File(file_name, mode=mode)\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/h5py/_hl/files.py\", line 394, in __init__\n",
      "    swmr=swmr)\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/h5py/_hl/files.py\", line 184, in make_fid\n",
      "    fid = h5f.create(name, h5f.ACC_EXCL, fapl=fapl, fcpl=fcpl)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5f.pyx\", line 105, in h5py.h5f.create\n",
      "OSError: Unable to create file (unable to open file: name = 'analyses/umi_Ca_4/ltj/kmeans/kmeans.feat-invca__tica_lag-10__k-75', errno = 2, error message = 'No such file or directory', flags = 15, o_flags = c2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:pyemma.coordinates.clustering.kmeans.KmeansClustering[61]:During saving the object KmeansClustering(clustercenters=array([[ 1.18436,  0.58214, ..., -0.15209,  0.61814],\n",
      "       [-0.21009, -0.0801 , ..., -0.06922, -0.02856],\n",
      "       ...,\n",
      "       [ 1.0011 ,  1.11453, ..., -0.45965,  0.40788],\n",
      "       [ 1.00974,  2.62235, ...,  1.54048, -1.06036]], dtype=float32),\n",
      "         fixed_seed=2125135720, init_strategy='kmeans++', keep_data=False,\n",
      "         max_iter=100, metric='euclidean', n_clusters=75, n_jobs=1,\n",
      "         oom_strategy='memmap', skip=0, stride=5, tolerance=1e-05)\") the following error occurred: Unable to create file (unable to open file: name = 'analyses/umi_Ca_4/ltj/kmeans/kmeans.feat-invca__tica_lag-10__k-75', errno = 2, error message = 'No such file or directory', flags = 15, o_flags = c2)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/h5py/_hl/files.py\", line 182, in make_fid\n",
      "    fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5f.pyx\", line 85, in h5py.h5f.open\n",
      "OSError: Unable to open file (unable to open file: name = 'analyses/umi_Ca_4/ltj/kmeans/kmeans.feat-invca__tica_lag-10__k-75', errno = 2, error message = 'No such file or directory', flags = 1, o_flags = 2)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/pyemma/_base/serialization/serialization.py\", line 240, in save\n",
      "    with H5File(file_name=file_name, mode='a') as f:\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/pyemma/_base/serialization/h5file.py\", line 41, in __init__\n",
      "    self._file = h5py.File(file_name, mode=mode)\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/h5py/_hl/files.py\", line 394, in __init__\n",
      "    swmr=swmr)\n",
      "  File \"/home/osz/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/h5py/_hl/files.py\", line 184, in make_fid\n",
      "    fid = h5f.create(name, h5f.ACC_EXCL, fapl=fapl, fcpl=fcpl)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5f.pyx\", line 105, in h5py.h5f.create\n",
      "OSError: Unable to create file (unable to open file: name = 'analyses/umi_Ca_4/ltj/kmeans/kmeans.feat-invca__tica_lag-10__k-75', errno = 2, error message = 'No such file or directory', flags = 15, o_flags = c2)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to create file (unable to open file: name = 'analyses/umi_Ca_4/ltj/kmeans/kmeans.feat-invca__tica_lag-10__k-75', errno = 2, error message = 'No such file or directory', flags = 15, o_flags = c2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m~/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'analyses/umi_Ca_4/ltj/kmeans/kmeans.feat-invca__tica_lag-10__k-75', errno = 2, error message = 'No such file or directory', flags = 1, o_flags = 2)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-a0b5e3ec51b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m                     tica_inp, **setup[\"kwargs\"])\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0msetup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"result\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_fkmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_streaming_chain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/pyemma/_base/serialization/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_name, model_name, overwrite, save_streaming_chain)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpyemma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh5file\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mH5File\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mH5File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_serializable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_streaming_chain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_streaming_chain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/pyemma/_base/serialization/h5file.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file_name, model_name, mode)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pyemma'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_model_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/admd/software/miniconda/envs/admd/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;31m# Try to open in append mode (read/write).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to create file (unable to open file: name = 'analyses/umi_Ca_4/ltj/kmeans/kmeans.feat-invca__tica_lag-10__k-75', errno = 2, error message = 'No such file or directory', flags = 15, o_flags = c2)"
     ]
    }
   ],
   "source": [
    "for feat, nm, dataset in aswa_tools.iter_models(all_models):\n",
    "    \n",
    "    dds = da / nm\n",
    "    dkmeans = dds / \"kmeans\"\n",
    "    fkmeans = dkmeans / \"kmeans.pyemma\"\n",
    "    \n",
    "    for setup in dataset[\"kmeans\"]:\n",
    "\n",
    "        if not dkmeans.is_dir(): dkmeans.mkdir(parents=True)\n",
    "\n",
    "        setup[\"hash\"] = thisone = _thisone_kmeans(feat, setup)\n",
    "        setup[\"timer\"] = timer = Timer(description=True, verbose=True)\n",
    "\n",
    "        inp = setup[\"input\"][\"result\"]\n",
    "        _fkmeans = fkmeans.with_suffix(\".%s\" % thisone)\n",
    "        \n",
    "        \n",
    "        if _fkmeans.is_file():\n",
    "            print(f\"Loading File: {_fkmeans}\")\n",
    "            with timer(yellowback+blacktxt+time_loadfile+rreset):\n",
    "                setup[\"result\"] = pyemma.load(_fkmeans)\n",
    "\n",
    "        else:\n",
    "            if not inp: continue\n",
    "\n",
    "            print(f\"Calculating and Saving to File: {_fkmeans}\")\n",
    "            inp._default_chunksize = 10000\n",
    "            tica_inp = inp.get_output(list(range(n_tica_dim)))\n",
    "            with timer(yellowback+blacktxt+time_calculation+rreset):\n",
    "                setup[\"result\"] = coor.cluster_kmeans(\n",
    "                    tica_inp, **setup[\"kwargs\"])\n",
    "\n",
    "            setup[\"result\"].save(_fkmeans, save_streaming_chain=True)\n",
    "\n",
    "\n",
    "print(dn1+\"  DONE LOADING DATA  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Many MSMs calculated to examine Implied TimeScales\n",
    "----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stepname = \"msm\"\n",
    "thiscalc = \"mits\"\n",
    "disc_methods = [\"kmeans\"]\n",
    "\n",
    "for feat, name, dataset in aswa_tools.iter_models(all_models):\n",
    "    \n",
    "    dds   = da / name\n",
    "    pmits = dds / stepname\n",
    "    fmits = pmits / f\"{thiscalc}.pyemma\"\n",
    "    #dmits = dataset[thiscalc] = list()\n",
    "    dmits = dataset[thiscalc] = dict()\n",
    "\n",
    "    if not pmits.is_dir(): pmits.mkdir(parents=True)\n",
    "\n",
    "    print(ts1+f\"MSMs for workflow: {name}\"+rreset)\n",
    "    for disc_method in disc_methods:\n",
    "        for inpsetup in dataset[f\"cluster_{disc_method}\"]:\n",
    "          \n",
    "            curmits = dict()\n",
    "            curmits[\"input\"] = inpsetup\n",
    "            curmits[\"timer\"] = timer = Timer(description=True, verbose=True)\n",
    "            curmits[\"kwargs\"] = dict(\n",
    "                lags=msm_lags,\n",
    "                reversible=reversible,\n",
    "                nits=10,\n",
    "                errors=\"bayes\",\n",
    "                nsamples=20,\n",
    "               # dt_traj=f\"{dataset['timestep']:0.2} ns\",\n",
    "                weights=\"empirical\",  # if nm==\"ltj\" else \"oom\",\n",
    "            )\n",
    "            \n",
    "            print(\"--------------------\")\n",
    "            curmits[\"hash\"] = thisone = _thisone_mits(feat, curmits)\n",
    "            _fmits = fmits.with_suffix(f\".{thisone}\")\n",
    "            \n",
    "            if not _fmits.is_file():\n",
    "                \n",
    "                if not inpsetup[\"result\"]: continue\n",
    "                print(f\"{is1}Calculating & Saving:{rreset} {thisone}\")\n",
    "                with timer(yellowback+blacktxt+time_calculation+rreset):\n",
    "                    resmits = pyemma.msm.timescales_msm(\n",
    "                        inpsetup[\"result\"].dtrajs,\n",
    "                        **curmits[\"kwargs\"])\n",
    "\n",
    "                resmits.save(_fmits)\n",
    "\n",
    "            else:\n",
    "                \n",
    "                print(is1+f\"Loading File:{rreset} {thisone}\")\n",
    "                with timer(yellowback+blacktxt+time_loadfile+rreset):\n",
    "                    resmits = pyemma.load(_fmits)\n",
    "\n",
    "            resmatrix = ImpliedTimescalesMatrix(resmits, n_macrostates, msm_lags)\n",
    "            curmits[\"result\"] = resmatrix\n",
    "            dmits[thisone] = curmits\n",
    "            \n",
    "            \n",
    "print(dn1+\"  DONE LOADING DATA  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index the msms separate from ITS objects for massive convenience\n",
    "  - just making separate object references to cleanup access\n",
    "  - later incorporated into PyEMMA patches\n",
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat, name, dataset in aswa_tools.iter_models(all_models):\n",
    "    \n",
    "    mms = dataset[\"msm\"] = dict())\n",
    "    \n",
    "    for thatone,setup in dataset[\"mits\"].items():\n",
    "        for mm in setup[\"result\"].its.models:\n",
    "\n",
    "            msmsetup = dict()\n",
    "            msmsetup[\"timer\"] = None\n",
    "            msmsetup[\"input\"] = setup[\"input\"]\n",
    "            msmsetup[\"result\"] = mm\n",
    "            msmsetup[\"kwargs\"] = {k:v for k,v in setup[\"kwargs\"].items() if k != \"lags\"}\n",
    "            msmsetup[\"kwargs\"].update({\"lag\": mm.lag})\n",
    "            msmsetup[\"hash\"] = thisone = _thisone_msm(feat, msmsetup)\n",
    "            mms[thisone] = msmsetup\n",
    "            \n",
    "\n",
    "print(colorama.Back.LIGHTBLACK_EX + colorama.Fore.BLUE + \"  DONE LOADING DATA  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCCA Calculation and Indexing\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for feat, name, dataset in aswa_tools.iter_models(all_models):\n",
    "    \n",
    "    dds   = da / name\n",
    "    ppcca = dds / \"pcca\"\n",
    "    fpcca = ppcca / \"pcca.pyemma\"\n",
    "    dpcca = dataset[\"pcca\"] = dict()\n",
    "\n",
    "    if not ppcca.is_dir(): ppcca.mkdir(parents=True)\n",
    "    print(ts1+f\"MSMs for workflow: {name}\"+rreset)\n",
    "\n",
    "    for nma in n_macrostates:\n",
    "        for msmsetup in dataset[\"msm\"]:\n",
    "\n",
    "            pccasetup = dict()\n",
    "            pccasetup[\"input\"] = inp = msmsetup\n",
    "            pccasetup[\"kwargs\"] = dict(m=nma)\n",
    "            pccasetup[\"timer\"] = timer = Timer(description=True, verbose=True)\n",
    "            pccasetup[\"hash\"] = thisone = _thisone_pcca(feat, pccasetup)\n",
    "            \n",
    "            _fpcca = fpcca.with_suffix(f\".{thisone}\")\n",
    "            \n",
    "            if _fpcca.is_file():\n",
    "                if not inp[\"result\"]: continue\n",
    "                print(is1+f\"Loading File: {thisone}\"+rreset)\n",
    "                with timer(yellowback+blacktxt+time_loadfile+rreset):\n",
    "                    respcca = pyemma.load(_fpcca)\n",
    "                \n",
    "            else:\n",
    "                print(is1+f\"Calculating & Saving: {thisone}\"+rreset)\n",
    "                try:\n",
    "                    with timer(yellowback+blacktxt+time_calculation+rreset):\n",
    "                        respcca = inp[\"result\"].pcca(nma)\n",
    "\n",
    "                    respcca.save(_fpcca)\n",
    "                    \n",
    "                except:\n",
    "                    print(yellowback+blacktxt+\"Calculation failed!\"+rreset)\n",
    "                    print(colorama.Fore.LIGHTRED_EX+blacktxt+traceback.format_exc()+rreset)\n",
    "                \n",
    "            pccasetup[\"result\"] = respcca\n",
    "            dpcca[thisone] = pccasetup\n",
    "            \n",
    "            \n",
    "print(colorama.Back.LIGHTBLACK_EX + colorama.Fore.BLUE + \"  DONE LOADING DATA  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMM Calculation\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stepname = \"hmm\"\n",
    "thiscalc = \"hits\"\n",
    "disc_methods = [\"kmeans\"]\n",
    "\n",
    "for feat, name, dataset in aswa_tools.iter_models(all_models):\n",
    "    \n",
    "    dds   = da / name\n",
    "    pmits = dds / stepname\n",
    "    fmits = pmits / f\"{thiscalc}.pyemma\"\n",
    "    dmits = dataset[thiscalc] = dict()\n",
    "\n",
    "    if not pmits.is_dir(): pmits.mkdir(parents=True)\n",
    "\n",
    "    print(f\"{ts1}MSMs for workflow: {name}{rreset}\")\n",
    "    \n",
    "    for disc_method in disc_methods:\n",
    "        for inpsetup in dataset[f\"cluster_{disc_method}\"]:\n",
    "            for nma in [2]:#n_macrostates:\n",
    "\n",
    "                curmits = dict()\n",
    "                curmits[\"input\"] = inpsetup\n",
    "                curmits[\"timer\"] = timer = Timer(description=True, verbose=True)\n",
    "                curmits[\"kwargs\"] = dict(\n",
    "                    lags=hmm_lags,\n",
    "                    nstates=nma,\n",
    "                    reversible=False,\n",
    "                    errors=\"bayes\",\n",
    "                    nsamples=20,\n",
    "                )\n",
    "\n",
    "                curmits[\"hash\"] = thisone = _thisone_hits(feat, curmits)\n",
    "                _fmits = fmits.with_suffix(f\".{thisone}\")\n",
    "            \n",
    "                print(\"--------------------\")\n",
    "                if not _fmits.is_file():\n",
    "                \n",
    "                    if not inpsetup[\"result\"]: continue\n",
    "                    print(f\"{is1}Calculating & Saving:{rreset} {thisone}\")\n",
    "                    try:\n",
    "                        with timer(yellowback+blacktxt+time_calculation+rreset):\n",
    "                            resmits = pyemma.msm.timescales_hmsm(\n",
    "                                inpsetup[\"result\"].dtrajs, **curmits[\"kwargs\"])\n",
    "\n",
    "                        resmits.save(_fmits)\n",
    "                        \n",
    "                    except:\n",
    "                        resmits = False\n",
    "\n",
    "                else:\n",
    "\n",
    "                    print(is1+f\"Loading File:{rreset} {thisone}\")\n",
    "                    with timer(yellowback+blacktxt+time_loadfile+rreset):\n",
    "                        resmits = pyemma.load(_fmits)\n",
    "\n",
    "                #resmatrix = ImpliedTimescalesMatrix(resmits, n_macrostates, msm_lags)\n",
    "                resmatrix = ImpliedTimescalesMatrix(resmits, [2], msm_lags)\n",
    "                curmits[\"result\"] = resmatrix\n",
    "                dmits[thisone] = curmits\n",
    "\n",
    "\n",
    "print(f\"{dn1}  DONE LOADING DATA  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reorganize analysis profiling data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''times = dict()\n",
    "\n",
    "for feat, name, dataset in aswa_tools.iter_models(all_models):\n",
    "    times[name] = dict()\n",
    "    for calc in (\"tica\", \"cluster_kmeans\", \"msm\", \"pcca\", \"hmm\"):\n",
    "\n",
    "        times[calc] = dict()\n",
    "        \n",
    "        if isinstance(dataset[calc], dict):\n",
    "            iterrer = dataset[calc].items()\n",
    "        elif isinstance(dataset[calc], list):\n",
    "            if calc == \"tica\": itto = _thisone_tica\n",
    "            elif calc == \"cluster_kmeans\": itto = _thisone_kmeans\n",
    "            else: raise ValueError\n",
    "            iterrer = iter((itto(feat, setup), setup) for setup in dataset[calc])\n",
    "        else:\n",
    "            raise TypeError\n",
    "            \n",
    "        for thisone, setup in iterrer:\n",
    "            pass\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\infty$ DONE\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(colorama.Back.LIGHTBLACK_EX + colorama.Fore.BLUE + \"  DONE LOADING DATA  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "-----------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
